//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-30411180
// Cuda compilation tools, release 11.5, V11.5.50
// Based on NVVM 7.0.1
//

.version 7.5
.target sm_52
.address_size 64

	// .globl	_Z16select_remove_ifPiS_iPVj7is_even
.shared .align 4 .u32 _ZZ13dynamic_wg_idPVjiE4gid_;
.shared .align 4 .b8 _ZZ24block_binary_prefix_sumsPiiE5sdata[4096];
// _ZZ16select_remove_ifPiS_iPVj7is_evenE5count has been demoted
// _ZZ14select_copy_ifPiS_iPVj7is_evenE5count has been demoted
.shared .align 4 .b8 _ZZ9reductionIiEvPT_S0_E5sdata[4096];

.visible .entry _Z16select_remove_ifPiS_iPVj7is_even(
	.param .u64 _Z16select_remove_ifPiS_iPVj7is_even_param_0,
	.param .u64 _Z16select_remove_ifPiS_iPVj7is_even_param_1,
	.param .u32 _Z16select_remove_ifPiS_iPVj7is_even_param_2,
	.param .u64 _Z16select_remove_ifPiS_iPVj7is_even_param_3,
	.param .align 1 .b8 _Z16select_remove_ifPiS_iPVj7is_even_param_4[1]
)
{
	.reg .pred 	%p<131>;
	.reg .b32 	%r<713>;
	.reg .b64 	%rd<75>;
	// demoted variable
	.shared .align 4 .u32 _ZZ16select_remove_ifPiS_iPVj7is_evenE5count;

	ld.param.u64 	%rd5, [_Z16select_remove_ifPiS_iPVj7is_even_param_0];
	ld.param.u64 	%rd6, [_Z16select_remove_ifPiS_iPVj7is_even_param_1];
	ld.param.u32 	%r191, [_Z16select_remove_ifPiS_iPVj7is_even_param_2];
	ld.param.u64 	%rd7, [_Z16select_remove_ifPiS_iPVj7is_even_param_3];
	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd5;
	cvta.to.global.u64 	%rd3, %rd7;
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r2, %r1, 4;
	mov.u32 	%r3, %tid.x;
	setp.ne.s32 	%p1, %r3, 0;
	@%p1 bra 	$L__BB0_2;

	div.u32 	%r192, %r191, %r2;
	mul.lo.s32 	%r193, %r192, %r2;
	sub.s32 	%r194, %r191, %r193;
	setp.ne.s32 	%p2, %r194, 0;
	mov.u32 	%r195, 0;
	selp.u32 	%r196, 1, 0, %p2;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r195;
	add.s32 	%r197, %r192, %r196;
	add.s32 	%r198, %r197, 1;
	mul.wide.s32 	%rd8, %r198, 4;
	add.s64 	%rd9, %rd3, %rd8;
	atom.global.add.u32 	%r199, [%rd9], 1;
	st.shared.u32 	[_ZZ13dynamic_wg_idPVjiE4gid_], %r199;

$L__BB0_2:
	bar.sync 	0;
	ld.shared.u32 	%r4, [_ZZ13dynamic_wg_idPVjiE4gid_];
	mov.u32 	%r674, 0;
	mad.lo.s32 	%r5, %r2, %r4, %r3;
	setp.ge.s32 	%p3, %r5, %r191;
	mov.u32 	%r701, -1;
	mov.u32 	%r671, %r701;
	@%p3 bra 	$L__BB0_4;

	mul.wide.s32 	%rd10, %r5, 4;
	add.s64 	%rd11, %rd1, %rd10;
	ld.global.u32 	%r202, [%rd11];
	and.b32  	%r674, %r202, 1;
	setp.eq.s32 	%p4, %r674, 0;
	selp.b32 	%r671, -1, %r202, %p4;

$L__BB0_4:
	add.s32 	%r10, %r5, %r1;
	setp.ge.s32 	%p5, %r10, %r191;
	mov.u32 	%r673, %r701;
	@%p5 bra 	$L__BB0_6;

	mul.wide.s32 	%rd12, %r10, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.u32 	%r204, [%rd13];
	and.b32  	%r205, %r204, 1;
	setp.eq.s32 	%p6, %r205, 0;
	selp.b32 	%r673, -1, %r204, %p6;
	add.s32 	%r674, %r674, %r205;

$L__BB0_6:
	add.s32 	%r15, %r10, %r1;
	setp.ge.s32 	%p7, %r15, %r191;
	mov.u32 	%r675, %r701;
	@%p7 bra 	$L__BB0_8;

	mul.wide.s32 	%rd14, %r15, 4;
	add.s64 	%rd15, %rd1, %rd14;
	ld.global.u32 	%r207, [%rd15];
	and.b32  	%r208, %r207, 1;
	setp.eq.s32 	%p8, %r208, 0;
	selp.b32 	%r675, -1, %r207, %p8;
	add.s32 	%r674, %r674, %r208;

$L__BB0_8:
	add.s32 	%r20, %r15, %r1;
	setp.ge.s32 	%p9, %r20, %r191;
	mov.u32 	%r677, %r701;
	@%p9 bra 	$L__BB0_10;

	mul.wide.s32 	%rd16, %r20, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.u32 	%r210, [%rd17];
	and.b32  	%r211, %r210, 1;
	setp.eq.s32 	%p10, %r211, 0;
	selp.b32 	%r677, -1, %r210, %p10;
	add.s32 	%r674, %r674, %r211;

$L__BB0_10:
	add.s32 	%r25, %r20, %r1;
	setp.ge.s32 	%p11, %r25, %r191;
	mov.u32 	%r679, %r701;
	@%p11 bra 	$L__BB0_12;

	mul.wide.s32 	%rd18, %r25, 4;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.u32 	%r213, [%rd19];
	and.b32  	%r214, %r213, 1;
	setp.eq.s32 	%p12, %r214, 0;
	selp.b32 	%r679, -1, %r213, %p12;
	add.s32 	%r674, %r674, %r214;

$L__BB0_12:
	add.s32 	%r30, %r25, %r1;
	setp.ge.s32 	%p13, %r30, %r191;
	mov.u32 	%r681, %r701;
	@%p13 bra 	$L__BB0_14;

	mul.wide.s32 	%rd20, %r30, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r216, [%rd21];
	and.b32  	%r217, %r216, 1;
	setp.eq.s32 	%p14, %r217, 0;
	selp.b32 	%r681, -1, %r216, %p14;
	add.s32 	%r674, %r674, %r217;

$L__BB0_14:
	add.s32 	%r35, %r30, %r1;
	setp.ge.s32 	%p15, %r35, %r191;
	mov.u32 	%r683, %r701;
	@%p15 bra 	$L__BB0_16;

	mul.wide.s32 	%rd22, %r35, 4;
	add.s64 	%rd23, %rd1, %rd22;
	ld.global.u32 	%r219, [%rd23];
	and.b32  	%r220, %r219, 1;
	setp.eq.s32 	%p16, %r220, 0;
	selp.b32 	%r683, -1, %r219, %p16;
	add.s32 	%r674, %r674, %r220;

$L__BB0_16:
	add.s32 	%r40, %r35, %r1;
	setp.ge.s32 	%p17, %r40, %r191;
	mov.u32 	%r685, %r701;
	@%p17 bra 	$L__BB0_18;

	mul.wide.s32 	%rd24, %r40, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.u32 	%r222, [%rd25];
	and.b32  	%r223, %r222, 1;
	setp.eq.s32 	%p18, %r223, 0;
	selp.b32 	%r685, -1, %r222, %p18;
	add.s32 	%r674, %r674, %r223;

$L__BB0_18:
	add.s32 	%r45, %r40, %r1;
	setp.ge.s32 	%p19, %r45, %r191;
	mov.u32 	%r687, %r701;
	@%p19 bra 	$L__BB0_20;

	mul.wide.s32 	%rd26, %r45, 4;
	add.s64 	%rd27, %rd1, %rd26;
	ld.global.u32 	%r225, [%rd27];
	and.b32  	%r226, %r225, 1;
	setp.eq.s32 	%p20, %r226, 0;
	selp.b32 	%r687, -1, %r225, %p20;
	add.s32 	%r674, %r674, %r226;

$L__BB0_20:
	add.s32 	%r50, %r45, %r1;
	setp.ge.s32 	%p21, %r50, %r191;
	mov.u32 	%r689, %r701;
	@%p21 bra 	$L__BB0_22;

	mul.wide.s32 	%rd28, %r50, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.u32 	%r228, [%rd29];
	and.b32  	%r229, %r228, 1;
	setp.eq.s32 	%p22, %r229, 0;
	selp.b32 	%r689, -1, %r228, %p22;
	add.s32 	%r674, %r674, %r229;

$L__BB0_22:
	add.s32 	%r55, %r50, %r1;
	setp.ge.s32 	%p23, %r55, %r191;
	mov.u32 	%r691, %r701;
	@%p23 bra 	$L__BB0_24;

	mul.wide.s32 	%rd30, %r55, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.global.u32 	%r231, [%rd31];
	and.b32  	%r232, %r231, 1;
	setp.eq.s32 	%p24, %r232, 0;
	selp.b32 	%r691, -1, %r231, %p24;
	add.s32 	%r674, %r674, %r232;

$L__BB0_24:
	add.s32 	%r60, %r55, %r1;
	setp.ge.s32 	%p25, %r60, %r191;
	mov.u32 	%r693, %r701;
	@%p25 bra 	$L__BB0_26;

	mul.wide.s32 	%rd32, %r60, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.u32 	%r234, [%rd33];
	and.b32  	%r235, %r234, 1;
	setp.eq.s32 	%p26, %r235, 0;
	selp.b32 	%r693, -1, %r234, %p26;
	add.s32 	%r674, %r674, %r235;

$L__BB0_26:
	add.s32 	%r65, %r60, %r1;
	setp.ge.s32 	%p27, %r65, %r191;
	mov.u32 	%r695, %r701;
	@%p27 bra 	$L__BB0_28;

	mul.wide.s32 	%rd34, %r65, 4;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.u32 	%r237, [%rd35];
	and.b32  	%r238, %r237, 1;
	setp.eq.s32 	%p28, %r238, 0;
	selp.b32 	%r695, -1, %r237, %p28;
	add.s32 	%r674, %r674, %r238;

$L__BB0_28:
	add.s32 	%r70, %r65, %r1;
	setp.ge.s32 	%p29, %r70, %r191;
	mov.u32 	%r697, %r701;
	@%p29 bra 	$L__BB0_30;

	mul.wide.s32 	%rd36, %r70, 4;
	add.s64 	%rd37, %rd1, %rd36;
	ld.global.u32 	%r240, [%rd37];
	and.b32  	%r241, %r240, 1;
	setp.eq.s32 	%p30, %r241, 0;
	selp.b32 	%r697, -1, %r240, %p30;
	add.s32 	%r674, %r674, %r241;

$L__BB0_30:
	add.s32 	%r75, %r70, %r1;
	setp.ge.s32 	%p31, %r75, %r191;
	mov.u32 	%r699, %r701;
	@%p31 bra 	$L__BB0_32;

	mul.wide.s32 	%rd38, %r75, 4;
	add.s64 	%rd39, %rd1, %rd38;
	ld.global.u32 	%r243, [%rd39];
	and.b32  	%r244, %r243, 1;
	setp.eq.s32 	%p32, %r244, 0;
	selp.b32 	%r699, -1, %r243, %p32;
	add.s32 	%r674, %r674, %r244;

$L__BB0_32:
	add.s32 	%r80, %r75, %r1;
	setp.ge.s32 	%p33, %r80, %r191;
	@%p33 bra 	$L__BB0_34;

	mul.wide.s32 	%rd40, %r80, 4;
	add.s64 	%rd41, %rd1, %rd40;
	ld.global.u32 	%r246, [%rd41];
	and.b32  	%r247, %r246, 1;
	setp.eq.s32 	%p34, %r247, 0;
	selp.b32 	%r701, -1, %r246, %p34;
	add.s32 	%r674, %r674, %r247;

$L__BB0_34:
	shl.b32 	%r248, %r3, 2;
	mov.u32 	%r249, _ZZ9reductionIiEvPT_S0_E5sdata;
	add.s32 	%r85, %r249, %r248;
	st.shared.u32 	[%r85], %r674;
	bar.sync 	0;
	setp.gt.u32 	%p35, %r3, 511;
	setp.lt.u32 	%p36, %r1, 1024;
	or.pred  	%p37, %p36, %p35;
	@%p37 bra 	$L__BB0_36;

	ld.shared.u32 	%r250, [%r85+2048];
	add.s32 	%r674, %r250, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_36:
	bar.sync 	0;
	setp.gt.u32 	%p38, %r3, 255;
	setp.lt.u32 	%p39, %r1, 512;
	or.pred  	%p40, %p39, %p38;
	@%p40 bra 	$L__BB0_38;

	ld.shared.u32 	%r251, [%r85+1024];
	add.s32 	%r674, %r251, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_38:
	bar.sync 	0;
	setp.gt.u32 	%p41, %r3, 127;
	setp.lt.u32 	%p42, %r1, 256;
	or.pred  	%p43, %p42, %p41;
	@%p43 bra 	$L__BB0_40;

	ld.shared.u32 	%r252, [%r85+512];
	add.s32 	%r674, %r252, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_40:
	bar.sync 	0;
	setp.gt.u32 	%p44, %r3, 63;
	setp.lt.u32 	%p45, %r1, 128;
	or.pred  	%p46, %p45, %p44;
	@%p46 bra 	$L__BB0_42;

	ld.shared.u32 	%r253, [%r85+256];
	add.s32 	%r674, %r253, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_42:
	bar.sync 	0;
	setp.gt.u32 	%p47, %r3, 31;
	setp.lt.u32 	%p48, %r1, 64;
	or.pred  	%p49, %p48, %p47;
	@%p49 bra 	$L__BB0_44;

	ld.shared.u32 	%r254, [%r85+128];
	add.s32 	%r674, %r254, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_44:
	bar.sync 	0;
	setp.gt.u32 	%p50, %r3, 15;
	setp.lt.u32 	%p51, %r1, 32;
	or.pred  	%p52, %p51, %p50;
	@%p52 bra 	$L__BB0_46;

	ld.shared.u32 	%r255, [%r85+64];
	add.s32 	%r674, %r255, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_46:
	bar.sync 	0;
	setp.gt.u32 	%p53, %r3, 7;
	setp.lt.u32 	%p54, %r1, 16;
	or.pred  	%p55, %p54, %p53;
	@%p55 bra 	$L__BB0_48;

	ld.shared.u32 	%r256, [%r85+32];
	add.s32 	%r674, %r256, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_48:
	bar.sync 	0;
	setp.gt.u32 	%p56, %r3, 3;
	setp.lt.u32 	%p57, %r1, 8;
	or.pred  	%p58, %p57, %p56;
	@%p58 bra 	$L__BB0_50;

	ld.shared.u32 	%r257, [%r85+16];
	add.s32 	%r674, %r257, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_50:
	bar.sync 	0;
	setp.gt.u32 	%p59, %r3, 1;
	setp.lt.u32 	%p60, %r1, 4;
	or.pred  	%p61, %p60, %p59;
	@%p61 bra 	$L__BB0_52;

	ld.shared.u32 	%r258, [%r85+8];
	add.s32 	%r674, %r258, %r674;
	st.shared.u32 	[%r85], %r674;

$L__BB0_52:
	bar.sync 	0;
	setp.lt.u32 	%p62, %r1, 2;
	or.pred  	%p64, %p62, %p1;
	@%p64 bra 	$L__BB0_54;

	ld.shared.u32 	%r259, [_ZZ9reductionIiEvPT_S0_E5sdata+4];
	add.s32 	%r674, %r259, %r674;
	st.shared.u32 	[_ZZ9reductionIiEvPT_S0_E5sdata], %r674;

$L__BB0_54:
	bar.sync 	0;
	@%p1 bra 	$L__BB0_58;

	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r674;
	mul.wide.s32 	%rd42, %r4, 4;
	add.s64 	%rd4, %rd3, %rd42;

$L__BB0_56:
	ld.volatile.global.u32 	%r260, [%rd4];
	setp.eq.s32 	%p66, %r260, 0;
	@%p66 bra 	$L__BB0_56;

	ld.volatile.global.u32 	%r261, [%rd4];
	add.s32 	%r262, %r674, %r261;
	st.volatile.global.u32 	[%rd4+4], %r262;
	add.s32 	%r263, %r261, -1;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r263;

$L__BB0_58:
	bar.sync 	0;
	shr.u32 	%r266, %r671, 31;
	xor.b32  	%r265, %r266, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r265, 0; 
	vote.ballot.b32 	%r264, %p1; 
	}
	// end inline asm
	and.b32  	%r107, %r3, 31;
	mov.u32 	%r267, -1;
	shl.b32 	%r268, %r267, %r107;
	not.b32 	%r108, %r268;
	and.b32  	%r269, %r264, %r108;
	popc.b32 	%r109, %r269;
	setp.ne.s32 	%p67, %r107, 31;
	shr.u32 	%r270, %r3, 3;
	and.b32  	%r271, %r270, 536870908;
	mov.u32 	%r272, _ZZ24block_binary_prefix_sumsPiiE5sdata;
	add.s32 	%r110, %r272, %r271;
	@%p67 bra 	$L__BB0_60;

	add.s32 	%r273, %r109, %r265;
	st.shared.u32 	[%r110], %r273;

$L__BB0_60:
	bar.sync 	0;
	add.s32 	%r111, %r272, %r248;
	@%p47 bra 	$L__BB0_62;

	ld.shared.u32 	%r278, [%r111];
	mov.u32 	%r277, 1;
	mov.u32 	%r279, %r278;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r279, %r277, 0x0; @p add.s32 r0, r0, %r279; mov.s32 %r279, r0;}
	// end inline asm
	mov.u32 	%r280, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r279, %r280, 0x0; @p add.s32 r0, r0, %r279; mov.s32 %r279, r0;}
	// end inline asm
	mov.u32 	%r283, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r279, %r283, 0x0; @p add.s32 r0, r0, %r279; mov.s32 %r279, r0;}
	// end inline asm
	mov.u32 	%r286, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r279, %r286, 0x0; @p add.s32 r0, r0, %r279; mov.s32 %r279, r0;}
	// end inline asm
	mov.u32 	%r289, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r279, %r289, 0x0; @p add.s32 r0, r0, %r279; mov.s32 %r279, r0;}
	// end inline asm
	sub.s32 	%r291, %r279, %r278;
	st.shared.u32 	[%r111], %r291;

$L__BB0_62:
	bar.sync 	0;
	ld.shared.u32 	%r292, [%r110];
	add.s32 	%r112, %r292, %r109;
	ld.shared.u32 	%r113, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	add.s32 	%r114, %r1, -1;
	setp.ne.s32 	%p69, %r3, %r114;
	@%p69 bra 	$L__BB0_64;

	add.s32 	%r293, %r112, %r265;
	ld.shared.u32 	%r294, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r295, %r293, %r294;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r295;

$L__BB0_64:
	add.s32 	%r115, %r112, %r113;
	setp.lt.s32 	%p70, %r671, 0;
	@%p70 bra 	$L__BB0_66;

	mul.wide.s32 	%rd43, %r115, 4;
	add.s64 	%rd44, %rd2, %rd43;
	st.global.u32 	[%rd44], %r671;

$L__BB0_66:
	shr.u32 	%r298, %r673, 31;
	xor.b32  	%r297, %r298, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r297, 0; 
	vote.ballot.b32 	%r296, %p1; 
	}
	// end inline asm
	and.b32  	%r299, %r296, %r108;
	popc.b32 	%r117, %r299;
	@%p67 bra 	$L__BB0_68;

	add.s32 	%r300, %r117, %r297;
	st.shared.u32 	[%r110], %r300;

$L__BB0_68:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_70;

	ld.shared.u32 	%r303, [%r111];
	mov.u32 	%r302, 1;
	mov.u32 	%r304, %r303;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r304, %r302, 0x0; @p add.s32 r0, r0, %r304; mov.s32 %r304, r0;}
	// end inline asm
	mov.u32 	%r305, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r304, %r305, 0x0; @p add.s32 r0, r0, %r304; mov.s32 %r304, r0;}
	// end inline asm
	mov.u32 	%r308, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r304, %r308, 0x0; @p add.s32 r0, r0, %r304; mov.s32 %r304, r0;}
	// end inline asm
	mov.u32 	%r311, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r304, %r311, 0x0; @p add.s32 r0, r0, %r304; mov.s32 %r304, r0;}
	// end inline asm
	mov.u32 	%r314, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r304, %r314, 0x0; @p add.s32 r0, r0, %r304; mov.s32 %r304, r0;}
	// end inline asm
	sub.s32 	%r316, %r304, %r303;
	st.shared.u32 	[%r111], %r316;

$L__BB0_70:
	bar.sync 	0;
	ld.shared.u32 	%r317, [%r110];
	add.s32 	%r118, %r317, %r117;
	ld.shared.u32 	%r119, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_72;

	add.s32 	%r318, %r118, %r297;
	ld.shared.u32 	%r319, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r320, %r318, %r319;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r320;

$L__BB0_72:
	add.s32 	%r120, %r118, %r119;
	setp.lt.s32 	%p74, %r673, 0;
	@%p74 bra 	$L__BB0_74;

	mul.wide.s32 	%rd45, %r120, 4;
	add.s64 	%rd46, %rd2, %rd45;
	st.global.u32 	[%rd46], %r673;

$L__BB0_74:
	shr.u32 	%r323, %r675, 31;
	xor.b32  	%r322, %r323, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r322, 0; 
	vote.ballot.b32 	%r321, %p1; 
	}
	// end inline asm
	and.b32  	%r324, %r321, %r108;
	popc.b32 	%r122, %r324;
	@%p67 bra 	$L__BB0_76;

	add.s32 	%r325, %r122, %r322;
	st.shared.u32 	[%r110], %r325;

$L__BB0_76:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_78;

	ld.shared.u32 	%r328, [%r111];
	mov.u32 	%r327, 1;
	mov.u32 	%r329, %r328;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r329, %r327, 0x0; @p add.s32 r0, r0, %r329; mov.s32 %r329, r0;}
	// end inline asm
	mov.u32 	%r330, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r329, %r330, 0x0; @p add.s32 r0, r0, %r329; mov.s32 %r329, r0;}
	// end inline asm
	mov.u32 	%r333, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r329, %r333, 0x0; @p add.s32 r0, r0, %r329; mov.s32 %r329, r0;}
	// end inline asm
	mov.u32 	%r336, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r329, %r336, 0x0; @p add.s32 r0, r0, %r329; mov.s32 %r329, r0;}
	// end inline asm
	mov.u32 	%r339, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r329, %r339, 0x0; @p add.s32 r0, r0, %r329; mov.s32 %r329, r0;}
	// end inline asm
	sub.s32 	%r341, %r329, %r328;
	st.shared.u32 	[%r111], %r341;

$L__BB0_78:
	bar.sync 	0;
	ld.shared.u32 	%r342, [%r110];
	add.s32 	%r123, %r342, %r122;
	ld.shared.u32 	%r124, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_80;

	add.s32 	%r343, %r123, %r322;
	ld.shared.u32 	%r344, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r345, %r343, %r344;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r345;

$L__BB0_80:
	add.s32 	%r125, %r123, %r124;
	setp.lt.s32 	%p78, %r675, 0;
	@%p78 bra 	$L__BB0_82;

	mul.wide.s32 	%rd47, %r125, 4;
	add.s64 	%rd48, %rd2, %rd47;
	st.global.u32 	[%rd48], %r675;

$L__BB0_82:
	shr.u32 	%r348, %r677, 31;
	xor.b32  	%r347, %r348, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r347, 0; 
	vote.ballot.b32 	%r346, %p1; 
	}
	// end inline asm
	and.b32  	%r349, %r346, %r108;
	popc.b32 	%r127, %r349;
	@%p67 bra 	$L__BB0_84;

	add.s32 	%r350, %r127, %r347;
	st.shared.u32 	[%r110], %r350;

$L__BB0_84:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_86;

	ld.shared.u32 	%r353, [%r111];
	mov.u32 	%r352, 1;
	mov.u32 	%r354, %r353;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r354, %r352, 0x0; @p add.s32 r0, r0, %r354; mov.s32 %r354, r0;}
	// end inline asm
	mov.u32 	%r355, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r354, %r355, 0x0; @p add.s32 r0, r0, %r354; mov.s32 %r354, r0;}
	// end inline asm
	mov.u32 	%r358, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r354, %r358, 0x0; @p add.s32 r0, r0, %r354; mov.s32 %r354, r0;}
	// end inline asm
	mov.u32 	%r361, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r354, %r361, 0x0; @p add.s32 r0, r0, %r354; mov.s32 %r354, r0;}
	// end inline asm
	mov.u32 	%r364, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r354, %r364, 0x0; @p add.s32 r0, r0, %r354; mov.s32 %r354, r0;}
	// end inline asm
	sub.s32 	%r366, %r354, %r353;
	st.shared.u32 	[%r111], %r366;

$L__BB0_86:
	bar.sync 	0;
	ld.shared.u32 	%r367, [%r110];
	add.s32 	%r128, %r367, %r127;
	ld.shared.u32 	%r129, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_88;

	add.s32 	%r368, %r128, %r347;
	ld.shared.u32 	%r369, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r370, %r368, %r369;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r370;

$L__BB0_88:
	add.s32 	%r130, %r128, %r129;
	setp.lt.s32 	%p82, %r677, 0;
	@%p82 bra 	$L__BB0_90;

	mul.wide.s32 	%rd49, %r130, 4;
	add.s64 	%rd50, %rd2, %rd49;
	st.global.u32 	[%rd50], %r677;

$L__BB0_90:
	shr.u32 	%r373, %r679, 31;
	xor.b32  	%r372, %r373, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r372, 0; 
	vote.ballot.b32 	%r371, %p1; 
	}
	// end inline asm
	and.b32  	%r374, %r371, %r108;
	popc.b32 	%r132, %r374;
	@%p67 bra 	$L__BB0_92;

	add.s32 	%r375, %r132, %r372;
	st.shared.u32 	[%r110], %r375;

$L__BB0_92:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_94;

	ld.shared.u32 	%r378, [%r111];
	mov.u32 	%r377, 1;
	mov.u32 	%r379, %r378;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r379, %r377, 0x0; @p add.s32 r0, r0, %r379; mov.s32 %r379, r0;}
	// end inline asm
	mov.u32 	%r380, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r379, %r380, 0x0; @p add.s32 r0, r0, %r379; mov.s32 %r379, r0;}
	// end inline asm
	mov.u32 	%r383, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r379, %r383, 0x0; @p add.s32 r0, r0, %r379; mov.s32 %r379, r0;}
	// end inline asm
	mov.u32 	%r386, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r379, %r386, 0x0; @p add.s32 r0, r0, %r379; mov.s32 %r379, r0;}
	// end inline asm
	mov.u32 	%r389, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r379, %r389, 0x0; @p add.s32 r0, r0, %r379; mov.s32 %r379, r0;}
	// end inline asm
	sub.s32 	%r391, %r379, %r378;
	st.shared.u32 	[%r111], %r391;

$L__BB0_94:
	bar.sync 	0;
	ld.shared.u32 	%r392, [%r110];
	add.s32 	%r133, %r392, %r132;
	ld.shared.u32 	%r134, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_96;

	add.s32 	%r393, %r133, %r372;
	ld.shared.u32 	%r394, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r395, %r393, %r394;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r395;

$L__BB0_96:
	add.s32 	%r135, %r133, %r134;
	setp.lt.s32 	%p86, %r679, 0;
	@%p86 bra 	$L__BB0_98;

	mul.wide.s32 	%rd51, %r135, 4;
	add.s64 	%rd52, %rd2, %rd51;
	st.global.u32 	[%rd52], %r679;

$L__BB0_98:
	shr.u32 	%r398, %r681, 31;
	xor.b32  	%r397, %r398, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r397, 0; 
	vote.ballot.b32 	%r396, %p1; 
	}
	// end inline asm
	and.b32  	%r399, %r396, %r108;
	popc.b32 	%r137, %r399;
	@%p67 bra 	$L__BB0_100;

	add.s32 	%r400, %r137, %r397;
	st.shared.u32 	[%r110], %r400;

$L__BB0_100:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_102;

	ld.shared.u32 	%r403, [%r111];
	mov.u32 	%r402, 1;
	mov.u32 	%r404, %r403;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r404, %r402, 0x0; @p add.s32 r0, r0, %r404; mov.s32 %r404, r0;}
	// end inline asm
	mov.u32 	%r405, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r404, %r405, 0x0; @p add.s32 r0, r0, %r404; mov.s32 %r404, r0;}
	// end inline asm
	mov.u32 	%r408, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r404, %r408, 0x0; @p add.s32 r0, r0, %r404; mov.s32 %r404, r0;}
	// end inline asm
	mov.u32 	%r411, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r404, %r411, 0x0; @p add.s32 r0, r0, %r404; mov.s32 %r404, r0;}
	// end inline asm
	mov.u32 	%r414, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r404, %r414, 0x0; @p add.s32 r0, r0, %r404; mov.s32 %r404, r0;}
	// end inline asm
	sub.s32 	%r416, %r404, %r403;
	st.shared.u32 	[%r111], %r416;

$L__BB0_102:
	bar.sync 	0;
	ld.shared.u32 	%r417, [%r110];
	add.s32 	%r138, %r417, %r137;
	ld.shared.u32 	%r139, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_104;

	add.s32 	%r418, %r138, %r397;
	ld.shared.u32 	%r419, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r420, %r418, %r419;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r420;

$L__BB0_104:
	add.s32 	%r140, %r138, %r139;
	setp.lt.s32 	%p90, %r681, 0;
	@%p90 bra 	$L__BB0_106;

	mul.wide.s32 	%rd53, %r140, 4;
	add.s64 	%rd54, %rd2, %rd53;
	st.global.u32 	[%rd54], %r681;

$L__BB0_106:
	shr.u32 	%r423, %r683, 31;
	xor.b32  	%r422, %r423, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r422, 0; 
	vote.ballot.b32 	%r421, %p1; 
	}
	// end inline asm
	and.b32  	%r424, %r421, %r108;
	popc.b32 	%r142, %r424;
	@%p67 bra 	$L__BB0_108;

	add.s32 	%r425, %r142, %r422;
	st.shared.u32 	[%r110], %r425;

$L__BB0_108:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_110;

	ld.shared.u32 	%r428, [%r111];
	mov.u32 	%r427, 1;
	mov.u32 	%r429, %r428;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r429, %r427, 0x0; @p add.s32 r0, r0, %r429; mov.s32 %r429, r0;}
	// end inline asm
	mov.u32 	%r430, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r429, %r430, 0x0; @p add.s32 r0, r0, %r429; mov.s32 %r429, r0;}
	// end inline asm
	mov.u32 	%r433, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r429, %r433, 0x0; @p add.s32 r0, r0, %r429; mov.s32 %r429, r0;}
	// end inline asm
	mov.u32 	%r436, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r429, %r436, 0x0; @p add.s32 r0, r0, %r429; mov.s32 %r429, r0;}
	// end inline asm
	mov.u32 	%r439, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r429, %r439, 0x0; @p add.s32 r0, r0, %r429; mov.s32 %r429, r0;}
	// end inline asm
	sub.s32 	%r441, %r429, %r428;
	st.shared.u32 	[%r111], %r441;

$L__BB0_110:
	bar.sync 	0;
	ld.shared.u32 	%r442, [%r110];
	add.s32 	%r143, %r442, %r142;
	ld.shared.u32 	%r144, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_112;

	add.s32 	%r443, %r143, %r422;
	ld.shared.u32 	%r444, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r445, %r443, %r444;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r445;

$L__BB0_112:
	add.s32 	%r145, %r143, %r144;
	setp.lt.s32 	%p94, %r683, 0;
	@%p94 bra 	$L__BB0_114;

	mul.wide.s32 	%rd55, %r145, 4;
	add.s64 	%rd56, %rd2, %rd55;
	st.global.u32 	[%rd56], %r683;

$L__BB0_114:
	shr.u32 	%r448, %r685, 31;
	xor.b32  	%r447, %r448, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r447, 0; 
	vote.ballot.b32 	%r446, %p1; 
	}
	// end inline asm
	and.b32  	%r449, %r446, %r108;
	popc.b32 	%r147, %r449;
	@%p67 bra 	$L__BB0_116;

	add.s32 	%r450, %r147, %r447;
	st.shared.u32 	[%r110], %r450;

$L__BB0_116:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_118;

	ld.shared.u32 	%r453, [%r111];
	mov.u32 	%r452, 1;
	mov.u32 	%r454, %r453;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r454, %r452, 0x0; @p add.s32 r0, r0, %r454; mov.s32 %r454, r0;}
	// end inline asm
	mov.u32 	%r455, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r454, %r455, 0x0; @p add.s32 r0, r0, %r454; mov.s32 %r454, r0;}
	// end inline asm
	mov.u32 	%r458, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r454, %r458, 0x0; @p add.s32 r0, r0, %r454; mov.s32 %r454, r0;}
	// end inline asm
	mov.u32 	%r461, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r454, %r461, 0x0; @p add.s32 r0, r0, %r454; mov.s32 %r454, r0;}
	// end inline asm
	mov.u32 	%r464, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r454, %r464, 0x0; @p add.s32 r0, r0, %r454; mov.s32 %r454, r0;}
	// end inline asm
	sub.s32 	%r466, %r454, %r453;
	st.shared.u32 	[%r111], %r466;

$L__BB0_118:
	bar.sync 	0;
	ld.shared.u32 	%r467, [%r110];
	add.s32 	%r148, %r467, %r147;
	ld.shared.u32 	%r149, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_120;

	add.s32 	%r468, %r148, %r447;
	ld.shared.u32 	%r469, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r470, %r468, %r469;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r470;

$L__BB0_120:
	add.s32 	%r150, %r148, %r149;
	setp.lt.s32 	%p98, %r685, 0;
	@%p98 bra 	$L__BB0_122;

	mul.wide.s32 	%rd57, %r150, 4;
	add.s64 	%rd58, %rd2, %rd57;
	st.global.u32 	[%rd58], %r685;

$L__BB0_122:
	shr.u32 	%r473, %r687, 31;
	xor.b32  	%r472, %r473, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r472, 0; 
	vote.ballot.b32 	%r471, %p1; 
	}
	// end inline asm
	and.b32  	%r474, %r471, %r108;
	popc.b32 	%r152, %r474;
	@%p67 bra 	$L__BB0_124;

	add.s32 	%r475, %r152, %r472;
	st.shared.u32 	[%r110], %r475;

$L__BB0_124:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_126;

	ld.shared.u32 	%r478, [%r111];
	mov.u32 	%r477, 1;
	mov.u32 	%r479, %r478;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r479, %r477, 0x0; @p add.s32 r0, r0, %r479; mov.s32 %r479, r0;}
	// end inline asm
	mov.u32 	%r480, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r479, %r480, 0x0; @p add.s32 r0, r0, %r479; mov.s32 %r479, r0;}
	// end inline asm
	mov.u32 	%r483, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r479, %r483, 0x0; @p add.s32 r0, r0, %r479; mov.s32 %r479, r0;}
	// end inline asm
	mov.u32 	%r486, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r479, %r486, 0x0; @p add.s32 r0, r0, %r479; mov.s32 %r479, r0;}
	// end inline asm
	mov.u32 	%r489, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r479, %r489, 0x0; @p add.s32 r0, r0, %r479; mov.s32 %r479, r0;}
	// end inline asm
	sub.s32 	%r491, %r479, %r478;
	st.shared.u32 	[%r111], %r491;

$L__BB0_126:
	bar.sync 	0;
	ld.shared.u32 	%r492, [%r110];
	add.s32 	%r153, %r492, %r152;
	ld.shared.u32 	%r154, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_128;

	add.s32 	%r493, %r153, %r472;
	ld.shared.u32 	%r494, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r495, %r493, %r494;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r495;

$L__BB0_128:
	add.s32 	%r155, %r153, %r154;
	setp.lt.s32 	%p102, %r687, 0;
	@%p102 bra 	$L__BB0_130;

	mul.wide.s32 	%rd59, %r155, 4;
	add.s64 	%rd60, %rd2, %rd59;
	st.global.u32 	[%rd60], %r687;

$L__BB0_130:
	shr.u32 	%r498, %r689, 31;
	xor.b32  	%r497, %r498, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r497, 0; 
	vote.ballot.b32 	%r496, %p1; 
	}
	// end inline asm
	and.b32  	%r499, %r496, %r108;
	popc.b32 	%r157, %r499;
	@%p67 bra 	$L__BB0_132;

	add.s32 	%r500, %r157, %r497;
	st.shared.u32 	[%r110], %r500;

$L__BB0_132:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_134;

	ld.shared.u32 	%r503, [%r111];
	mov.u32 	%r502, 1;
	mov.u32 	%r504, %r503;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r504, %r502, 0x0; @p add.s32 r0, r0, %r504; mov.s32 %r504, r0;}
	// end inline asm
	mov.u32 	%r505, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r504, %r505, 0x0; @p add.s32 r0, r0, %r504; mov.s32 %r504, r0;}
	// end inline asm
	mov.u32 	%r508, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r504, %r508, 0x0; @p add.s32 r0, r0, %r504; mov.s32 %r504, r0;}
	// end inline asm
	mov.u32 	%r511, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r504, %r511, 0x0; @p add.s32 r0, r0, %r504; mov.s32 %r504, r0;}
	// end inline asm
	mov.u32 	%r514, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r504, %r514, 0x0; @p add.s32 r0, r0, %r504; mov.s32 %r504, r0;}
	// end inline asm
	sub.s32 	%r516, %r504, %r503;
	st.shared.u32 	[%r111], %r516;

$L__BB0_134:
	bar.sync 	0;
	ld.shared.u32 	%r517, [%r110];
	add.s32 	%r158, %r517, %r157;
	ld.shared.u32 	%r159, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_136;

	add.s32 	%r518, %r158, %r497;
	ld.shared.u32 	%r519, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r520, %r518, %r519;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r520;

$L__BB0_136:
	add.s32 	%r160, %r158, %r159;
	setp.lt.s32 	%p106, %r689, 0;
	@%p106 bra 	$L__BB0_138;

	mul.wide.s32 	%rd61, %r160, 4;
	add.s64 	%rd62, %rd2, %rd61;
	st.global.u32 	[%rd62], %r689;

$L__BB0_138:
	shr.u32 	%r523, %r691, 31;
	xor.b32  	%r522, %r523, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r522, 0; 
	vote.ballot.b32 	%r521, %p1; 
	}
	// end inline asm
	and.b32  	%r524, %r521, %r108;
	popc.b32 	%r162, %r524;
	@%p67 bra 	$L__BB0_140;

	add.s32 	%r525, %r162, %r522;
	st.shared.u32 	[%r110], %r525;

$L__BB0_140:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_142;

	ld.shared.u32 	%r528, [%r111];
	mov.u32 	%r527, 1;
	mov.u32 	%r529, %r528;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r529, %r527, 0x0; @p add.s32 r0, r0, %r529; mov.s32 %r529, r0;}
	// end inline asm
	mov.u32 	%r530, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r529, %r530, 0x0; @p add.s32 r0, r0, %r529; mov.s32 %r529, r0;}
	// end inline asm
	mov.u32 	%r533, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r529, %r533, 0x0; @p add.s32 r0, r0, %r529; mov.s32 %r529, r0;}
	// end inline asm
	mov.u32 	%r536, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r529, %r536, 0x0; @p add.s32 r0, r0, %r529; mov.s32 %r529, r0;}
	// end inline asm
	mov.u32 	%r539, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r529, %r539, 0x0; @p add.s32 r0, r0, %r529; mov.s32 %r529, r0;}
	// end inline asm
	sub.s32 	%r541, %r529, %r528;
	st.shared.u32 	[%r111], %r541;

$L__BB0_142:
	bar.sync 	0;
	ld.shared.u32 	%r542, [%r110];
	add.s32 	%r163, %r542, %r162;
	ld.shared.u32 	%r164, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_144;

	add.s32 	%r543, %r163, %r522;
	ld.shared.u32 	%r544, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r545, %r543, %r544;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r545;

$L__BB0_144:
	add.s32 	%r165, %r163, %r164;
	setp.lt.s32 	%p110, %r691, 0;
	@%p110 bra 	$L__BB0_146;

	mul.wide.s32 	%rd63, %r165, 4;
	add.s64 	%rd64, %rd2, %rd63;
	st.global.u32 	[%rd64], %r691;

$L__BB0_146:
	shr.u32 	%r548, %r693, 31;
	xor.b32  	%r547, %r548, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r547, 0; 
	vote.ballot.b32 	%r546, %p1; 
	}
	// end inline asm
	and.b32  	%r549, %r546, %r108;
	popc.b32 	%r167, %r549;
	@%p67 bra 	$L__BB0_148;

	add.s32 	%r550, %r167, %r547;
	st.shared.u32 	[%r110], %r550;

$L__BB0_148:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_150;

	ld.shared.u32 	%r553, [%r111];
	mov.u32 	%r552, 1;
	mov.u32 	%r554, %r553;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r554, %r552, 0x0; @p add.s32 r0, r0, %r554; mov.s32 %r554, r0;}
	// end inline asm
	mov.u32 	%r555, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r554, %r555, 0x0; @p add.s32 r0, r0, %r554; mov.s32 %r554, r0;}
	// end inline asm
	mov.u32 	%r558, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r554, %r558, 0x0; @p add.s32 r0, r0, %r554; mov.s32 %r554, r0;}
	// end inline asm
	mov.u32 	%r561, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r554, %r561, 0x0; @p add.s32 r0, r0, %r554; mov.s32 %r554, r0;}
	// end inline asm
	mov.u32 	%r564, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r554, %r564, 0x0; @p add.s32 r0, r0, %r554; mov.s32 %r554, r0;}
	// end inline asm
	sub.s32 	%r566, %r554, %r553;
	st.shared.u32 	[%r111], %r566;

$L__BB0_150:
	bar.sync 	0;
	ld.shared.u32 	%r567, [%r110];
	add.s32 	%r168, %r567, %r167;
	ld.shared.u32 	%r169, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_152;

	add.s32 	%r568, %r168, %r547;
	ld.shared.u32 	%r569, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r570, %r568, %r569;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r570;

$L__BB0_152:
	add.s32 	%r170, %r168, %r169;
	setp.lt.s32 	%p114, %r693, 0;
	@%p114 bra 	$L__BB0_154;

	mul.wide.s32 	%rd65, %r170, 4;
	add.s64 	%rd66, %rd2, %rd65;
	st.global.u32 	[%rd66], %r693;

$L__BB0_154:
	shr.u32 	%r573, %r695, 31;
	xor.b32  	%r572, %r573, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r572, 0; 
	vote.ballot.b32 	%r571, %p1; 
	}
	// end inline asm
	and.b32  	%r574, %r571, %r108;
	popc.b32 	%r172, %r574;
	@%p67 bra 	$L__BB0_156;

	add.s32 	%r575, %r172, %r572;
	st.shared.u32 	[%r110], %r575;

$L__BB0_156:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_158;

	ld.shared.u32 	%r578, [%r111];
	mov.u32 	%r577, 1;
	mov.u32 	%r579, %r578;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r579, %r577, 0x0; @p add.s32 r0, r0, %r579; mov.s32 %r579, r0;}
	// end inline asm
	mov.u32 	%r580, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r579, %r580, 0x0; @p add.s32 r0, r0, %r579; mov.s32 %r579, r0;}
	// end inline asm
	mov.u32 	%r583, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r579, %r583, 0x0; @p add.s32 r0, r0, %r579; mov.s32 %r579, r0;}
	// end inline asm
	mov.u32 	%r586, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r579, %r586, 0x0; @p add.s32 r0, r0, %r579; mov.s32 %r579, r0;}
	// end inline asm
	mov.u32 	%r589, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r579, %r589, 0x0; @p add.s32 r0, r0, %r579; mov.s32 %r579, r0;}
	// end inline asm
	sub.s32 	%r591, %r579, %r578;
	st.shared.u32 	[%r111], %r591;

$L__BB0_158:
	bar.sync 	0;
	ld.shared.u32 	%r592, [%r110];
	add.s32 	%r173, %r592, %r172;
	ld.shared.u32 	%r174, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_160;

	add.s32 	%r593, %r173, %r572;
	ld.shared.u32 	%r594, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r595, %r593, %r594;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r595;

$L__BB0_160:
	add.s32 	%r175, %r173, %r174;
	setp.lt.s32 	%p118, %r695, 0;
	@%p118 bra 	$L__BB0_162;

	mul.wide.s32 	%rd67, %r175, 4;
	add.s64 	%rd68, %rd2, %rd67;
	st.global.u32 	[%rd68], %r695;

$L__BB0_162:
	shr.u32 	%r598, %r697, 31;
	xor.b32  	%r597, %r598, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r597, 0; 
	vote.ballot.b32 	%r596, %p1; 
	}
	// end inline asm
	and.b32  	%r599, %r596, %r108;
	popc.b32 	%r177, %r599;
	@%p67 bra 	$L__BB0_164;

	add.s32 	%r600, %r177, %r597;
	st.shared.u32 	[%r110], %r600;

$L__BB0_164:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_166;

	ld.shared.u32 	%r603, [%r111];
	mov.u32 	%r602, 1;
	mov.u32 	%r604, %r603;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r604, %r602, 0x0; @p add.s32 r0, r0, %r604; mov.s32 %r604, r0;}
	// end inline asm
	mov.u32 	%r605, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r604, %r605, 0x0; @p add.s32 r0, r0, %r604; mov.s32 %r604, r0;}
	// end inline asm
	mov.u32 	%r608, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r604, %r608, 0x0; @p add.s32 r0, r0, %r604; mov.s32 %r604, r0;}
	// end inline asm
	mov.u32 	%r611, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r604, %r611, 0x0; @p add.s32 r0, r0, %r604; mov.s32 %r604, r0;}
	// end inline asm
	mov.u32 	%r614, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r604, %r614, 0x0; @p add.s32 r0, r0, %r604; mov.s32 %r604, r0;}
	// end inline asm
	sub.s32 	%r616, %r604, %r603;
	st.shared.u32 	[%r111], %r616;

$L__BB0_166:
	bar.sync 	0;
	ld.shared.u32 	%r617, [%r110];
	add.s32 	%r178, %r617, %r177;
	ld.shared.u32 	%r179, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_168;

	add.s32 	%r618, %r178, %r597;
	ld.shared.u32 	%r619, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r620, %r618, %r619;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r620;

$L__BB0_168:
	add.s32 	%r180, %r178, %r179;
	setp.lt.s32 	%p122, %r697, 0;
	@%p122 bra 	$L__BB0_170;

	mul.wide.s32 	%rd69, %r180, 4;
	add.s64 	%rd70, %rd2, %rd69;
	st.global.u32 	[%rd70], %r697;

$L__BB0_170:
	shr.u32 	%r623, %r699, 31;
	xor.b32  	%r622, %r623, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r622, 0; 
	vote.ballot.b32 	%r621, %p1; 
	}
	// end inline asm
	and.b32  	%r624, %r621, %r108;
	popc.b32 	%r182, %r624;
	@%p67 bra 	$L__BB0_172;

	add.s32 	%r625, %r182, %r622;
	st.shared.u32 	[%r110], %r625;

$L__BB0_172:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_174;

	ld.shared.u32 	%r628, [%r111];
	mov.u32 	%r627, 1;
	mov.u32 	%r629, %r628;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r629, %r627, 0x0; @p add.s32 r0, r0, %r629; mov.s32 %r629, r0;}
	// end inline asm
	mov.u32 	%r630, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r629, %r630, 0x0; @p add.s32 r0, r0, %r629; mov.s32 %r629, r0;}
	// end inline asm
	mov.u32 	%r633, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r629, %r633, 0x0; @p add.s32 r0, r0, %r629; mov.s32 %r629, r0;}
	// end inline asm
	mov.u32 	%r636, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r629, %r636, 0x0; @p add.s32 r0, r0, %r629; mov.s32 %r629, r0;}
	// end inline asm
	mov.u32 	%r639, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r629, %r639, 0x0; @p add.s32 r0, r0, %r629; mov.s32 %r629, r0;}
	// end inline asm
	sub.s32 	%r641, %r629, %r628;
	st.shared.u32 	[%r111], %r641;

$L__BB0_174:
	bar.sync 	0;
	ld.shared.u32 	%r642, [%r110];
	add.s32 	%r183, %r642, %r182;
	ld.shared.u32 	%r184, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_176;

	add.s32 	%r643, %r183, %r622;
	ld.shared.u32 	%r644, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r645, %r643, %r644;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r645;

$L__BB0_176:
	add.s32 	%r185, %r183, %r184;
	setp.lt.s32 	%p126, %r699, 0;
	@%p126 bra 	$L__BB0_178;

	mul.wide.s32 	%rd71, %r185, 4;
	add.s64 	%rd72, %rd2, %rd71;
	st.global.u32 	[%rd72], %r699;

$L__BB0_178:
	shr.u32 	%r648, %r701, 31;
	xor.b32  	%r647, %r648, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r647, 0; 
	vote.ballot.b32 	%r646, %p1; 
	}
	// end inline asm
	and.b32  	%r649, %r646, %r108;
	popc.b32 	%r187, %r649;
	@%p67 bra 	$L__BB0_180;

	add.s32 	%r650, %r187, %r647;
	st.shared.u32 	[%r110], %r650;

$L__BB0_180:
	bar.sync 	0;
	@%p47 bra 	$L__BB0_182;

	ld.shared.u32 	%r653, [%r111];
	mov.u32 	%r652, 1;
	mov.u32 	%r654, %r653;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r654, %r652, 0x0; @p add.s32 r0, r0, %r654; mov.s32 %r654, r0;}
	// end inline asm
	mov.u32 	%r655, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r654, %r655, 0x0; @p add.s32 r0, r0, %r654; mov.s32 %r654, r0;}
	// end inline asm
	mov.u32 	%r658, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r654, %r658, 0x0; @p add.s32 r0, r0, %r654; mov.s32 %r654, r0;}
	// end inline asm
	mov.u32 	%r661, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r654, %r661, 0x0; @p add.s32 r0, r0, %r654; mov.s32 %r654, r0;}
	// end inline asm
	mov.u32 	%r664, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r654, %r664, 0x0; @p add.s32 r0, r0, %r654; mov.s32 %r654, r0;}
	// end inline asm
	sub.s32 	%r666, %r654, %r653;
	st.shared.u32 	[%r111], %r666;

$L__BB0_182:
	bar.sync 	0;
	ld.shared.u32 	%r667, [%r110];
	add.s32 	%r188, %r667, %r187;
	ld.shared.u32 	%r189, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p69 bra 	$L__BB0_184;

	add.s32 	%r668, %r188, %r647;
	ld.shared.u32 	%r669, [_ZZ16select_remove_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r670, %r668, %r669;
	st.shared.u32 	[_ZZ16select_remove_ifPiS_iPVj7is_evenE5count], %r670;

$L__BB0_184:
	add.s32 	%r190, %r188, %r189;
	setp.lt.s32 	%p130, %r701, 0;
	@%p130 bra 	$L__BB0_186;

	mul.wide.s32 	%rd73, %r190, 4;
	add.s64 	%rd74, %rd2, %rd73;
	st.global.u32 	[%rd74], %r701;

$L__BB0_186:
	ret;

}
	// .globl	_Z14select_copy_ifPiS_iPVj7is_even
.visible .entry _Z14select_copy_ifPiS_iPVj7is_even(
	.param .u64 _Z14select_copy_ifPiS_iPVj7is_even_param_0,
	.param .u64 _Z14select_copy_ifPiS_iPVj7is_even_param_1,
	.param .u32 _Z14select_copy_ifPiS_iPVj7is_even_param_2,
	.param .u64 _Z14select_copy_ifPiS_iPVj7is_even_param_3,
	.param .align 1 .b8 _Z14select_copy_ifPiS_iPVj7is_even_param_4[1]
)
{
	.reg .pred 	%p<147>;
	.reg .b32 	%r<729>;
	.reg .b64 	%rd<75>;
	// demoted variable
	.shared .align 4 .u32 _ZZ14select_copy_ifPiS_iPVj7is_evenE5count;

	ld.param.u64 	%rd5, [_Z14select_copy_ifPiS_iPVj7is_even_param_0];
	ld.param.u64 	%rd6, [_Z14select_copy_ifPiS_iPVj7is_even_param_1];
	ld.param.u32 	%r191, [_Z14select_copy_ifPiS_iPVj7is_even_param_2];
	ld.param.u64 	%rd7, [_Z14select_copy_ifPiS_iPVj7is_even_param_3];
	cvta.to.global.u64 	%rd1, %rd6;
	cvta.to.global.u64 	%rd2, %rd5;
	cvta.to.global.u64 	%rd3, %rd7;
	mov.u32 	%r1, %ntid.x;
	shl.b32 	%r2, %r1, 4;
	mov.u32 	%r3, %tid.x;
	setp.ne.s32 	%p1, %r3, 0;
	@%p1 bra 	$L__BB1_2;

	div.u32 	%r192, %r191, %r2;
	mul.lo.s32 	%r193, %r192, %r2;
	sub.s32 	%r194, %r191, %r193;
	setp.ne.s32 	%p2, %r194, 0;
	mov.u32 	%r195, 0;
	selp.u32 	%r196, 1, 0, %p2;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r195;
	add.s32 	%r197, %r192, %r196;
	add.s32 	%r198, %r197, 1;
	mul.wide.s32 	%rd8, %r198, 4;
	add.s64 	%rd9, %rd3, %rd8;
	atom.global.add.u32 	%r199, [%rd9], 1;
	st.shared.u32 	[_ZZ13dynamic_wg_idPVjiE4gid_], %r199;

$L__BB1_2:
	bar.sync 	0;
	ld.shared.u32 	%r4, [_ZZ13dynamic_wg_idPVjiE4gid_];
	mov.u32 	%r690, 0;
	mad.lo.s32 	%r5, %r2, %r4, %r3;
	setp.ge.s32 	%p3, %r5, %r191;
	mov.u32 	%r717, -1;
	mov.u32 	%r687, %r717;
	@%p3 bra 	$L__BB1_4;

	mul.wide.s32 	%rd10, %r5, 4;
	add.s64 	%rd11, %rd1, %rd10;
	ld.global.u32 	%r202, [%rd11];
	and.b32  	%r203, %r202, 1;
	setp.eq.b32 	%p4, %r203, 1;
	not.pred 	%p5, %p4;
	selp.b32 	%r687, -1, %r202, %p4;
	selp.u32 	%r690, 1, 0, %p5;

$L__BB1_4:
	add.s32 	%r10, %r5, %r1;
	setp.ge.s32 	%p6, %r10, %r191;
	mov.u32 	%r689, %r717;
	@%p6 bra 	$L__BB1_6;

	mul.wide.s32 	%rd12, %r10, 4;
	add.s64 	%rd13, %rd1, %rd12;
	ld.global.u32 	%r205, [%rd13];
	and.b32  	%r206, %r205, 1;
	setp.eq.b32 	%p7, %r206, 1;
	not.pred 	%p8, %p7;
	selp.b32 	%r689, -1, %r205, %p7;
	selp.u32 	%r207, 1, 0, %p8;
	add.s32 	%r690, %r690, %r207;

$L__BB1_6:
	add.s32 	%r15, %r10, %r1;
	setp.ge.s32 	%p9, %r15, %r191;
	mov.u32 	%r691, %r717;
	@%p9 bra 	$L__BB1_8;

	mul.wide.s32 	%rd14, %r15, 4;
	add.s64 	%rd15, %rd1, %rd14;
	ld.global.u32 	%r209, [%rd15];
	and.b32  	%r210, %r209, 1;
	setp.eq.b32 	%p10, %r210, 1;
	not.pred 	%p11, %p10;
	selp.b32 	%r691, -1, %r209, %p10;
	selp.u32 	%r211, 1, 0, %p11;
	add.s32 	%r690, %r690, %r211;

$L__BB1_8:
	add.s32 	%r20, %r15, %r1;
	setp.ge.s32 	%p12, %r20, %r191;
	mov.u32 	%r693, %r717;
	@%p12 bra 	$L__BB1_10;

	mul.wide.s32 	%rd16, %r20, 4;
	add.s64 	%rd17, %rd1, %rd16;
	ld.global.u32 	%r213, [%rd17];
	and.b32  	%r214, %r213, 1;
	setp.eq.b32 	%p13, %r214, 1;
	not.pred 	%p14, %p13;
	selp.b32 	%r693, -1, %r213, %p13;
	selp.u32 	%r215, 1, 0, %p14;
	add.s32 	%r690, %r690, %r215;

$L__BB1_10:
	add.s32 	%r25, %r20, %r1;
	setp.ge.s32 	%p15, %r25, %r191;
	mov.u32 	%r695, %r717;
	@%p15 bra 	$L__BB1_12;

	mul.wide.s32 	%rd18, %r25, 4;
	add.s64 	%rd19, %rd1, %rd18;
	ld.global.u32 	%r217, [%rd19];
	and.b32  	%r218, %r217, 1;
	setp.eq.b32 	%p16, %r218, 1;
	not.pred 	%p17, %p16;
	selp.b32 	%r695, -1, %r217, %p16;
	selp.u32 	%r219, 1, 0, %p17;
	add.s32 	%r690, %r690, %r219;

$L__BB1_12:
	add.s32 	%r30, %r25, %r1;
	setp.ge.s32 	%p18, %r30, %r191;
	mov.u32 	%r697, %r717;
	@%p18 bra 	$L__BB1_14;

	mul.wide.s32 	%rd20, %r30, 4;
	add.s64 	%rd21, %rd1, %rd20;
	ld.global.u32 	%r221, [%rd21];
	and.b32  	%r222, %r221, 1;
	setp.eq.b32 	%p19, %r222, 1;
	not.pred 	%p20, %p19;
	selp.b32 	%r697, -1, %r221, %p19;
	selp.u32 	%r223, 1, 0, %p20;
	add.s32 	%r690, %r690, %r223;

$L__BB1_14:
	add.s32 	%r35, %r30, %r1;
	setp.ge.s32 	%p21, %r35, %r191;
	mov.u32 	%r699, %r717;
	@%p21 bra 	$L__BB1_16;

	mul.wide.s32 	%rd22, %r35, 4;
	add.s64 	%rd23, %rd1, %rd22;
	ld.global.u32 	%r225, [%rd23];
	and.b32  	%r226, %r225, 1;
	setp.eq.b32 	%p22, %r226, 1;
	not.pred 	%p23, %p22;
	selp.b32 	%r699, -1, %r225, %p22;
	selp.u32 	%r227, 1, 0, %p23;
	add.s32 	%r690, %r690, %r227;

$L__BB1_16:
	add.s32 	%r40, %r35, %r1;
	setp.ge.s32 	%p24, %r40, %r191;
	mov.u32 	%r701, %r717;
	@%p24 bra 	$L__BB1_18;

	mul.wide.s32 	%rd24, %r40, 4;
	add.s64 	%rd25, %rd1, %rd24;
	ld.global.u32 	%r229, [%rd25];
	and.b32  	%r230, %r229, 1;
	setp.eq.b32 	%p25, %r230, 1;
	not.pred 	%p26, %p25;
	selp.b32 	%r701, -1, %r229, %p25;
	selp.u32 	%r231, 1, 0, %p26;
	add.s32 	%r690, %r690, %r231;

$L__BB1_18:
	add.s32 	%r45, %r40, %r1;
	setp.ge.s32 	%p27, %r45, %r191;
	mov.u32 	%r703, %r717;
	@%p27 bra 	$L__BB1_20;

	mul.wide.s32 	%rd26, %r45, 4;
	add.s64 	%rd27, %rd1, %rd26;
	ld.global.u32 	%r233, [%rd27];
	and.b32  	%r234, %r233, 1;
	setp.eq.b32 	%p28, %r234, 1;
	not.pred 	%p29, %p28;
	selp.b32 	%r703, -1, %r233, %p28;
	selp.u32 	%r235, 1, 0, %p29;
	add.s32 	%r690, %r690, %r235;

$L__BB1_20:
	add.s32 	%r50, %r45, %r1;
	setp.ge.s32 	%p30, %r50, %r191;
	mov.u32 	%r705, %r717;
	@%p30 bra 	$L__BB1_22;

	mul.wide.s32 	%rd28, %r50, 4;
	add.s64 	%rd29, %rd1, %rd28;
	ld.global.u32 	%r237, [%rd29];
	and.b32  	%r238, %r237, 1;
	setp.eq.b32 	%p31, %r238, 1;
	not.pred 	%p32, %p31;
	selp.b32 	%r705, -1, %r237, %p31;
	selp.u32 	%r239, 1, 0, %p32;
	add.s32 	%r690, %r690, %r239;

$L__BB1_22:
	add.s32 	%r55, %r50, %r1;
	setp.ge.s32 	%p33, %r55, %r191;
	mov.u32 	%r707, %r717;
	@%p33 bra 	$L__BB1_24;

	mul.wide.s32 	%rd30, %r55, 4;
	add.s64 	%rd31, %rd1, %rd30;
	ld.global.u32 	%r241, [%rd31];
	and.b32  	%r242, %r241, 1;
	setp.eq.b32 	%p34, %r242, 1;
	not.pred 	%p35, %p34;
	selp.b32 	%r707, -1, %r241, %p34;
	selp.u32 	%r243, 1, 0, %p35;
	add.s32 	%r690, %r690, %r243;

$L__BB1_24:
	add.s32 	%r60, %r55, %r1;
	setp.ge.s32 	%p36, %r60, %r191;
	mov.u32 	%r709, %r717;
	@%p36 bra 	$L__BB1_26;

	mul.wide.s32 	%rd32, %r60, 4;
	add.s64 	%rd33, %rd1, %rd32;
	ld.global.u32 	%r245, [%rd33];
	and.b32  	%r246, %r245, 1;
	setp.eq.b32 	%p37, %r246, 1;
	not.pred 	%p38, %p37;
	selp.b32 	%r709, -1, %r245, %p37;
	selp.u32 	%r247, 1, 0, %p38;
	add.s32 	%r690, %r690, %r247;

$L__BB1_26:
	add.s32 	%r65, %r60, %r1;
	setp.ge.s32 	%p39, %r65, %r191;
	mov.u32 	%r711, %r717;
	@%p39 bra 	$L__BB1_28;

	mul.wide.s32 	%rd34, %r65, 4;
	add.s64 	%rd35, %rd1, %rd34;
	ld.global.u32 	%r249, [%rd35];
	and.b32  	%r250, %r249, 1;
	setp.eq.b32 	%p40, %r250, 1;
	not.pred 	%p41, %p40;
	selp.b32 	%r711, -1, %r249, %p40;
	selp.u32 	%r251, 1, 0, %p41;
	add.s32 	%r690, %r690, %r251;

$L__BB1_28:
	add.s32 	%r70, %r65, %r1;
	setp.ge.s32 	%p42, %r70, %r191;
	mov.u32 	%r713, %r717;
	@%p42 bra 	$L__BB1_30;

	mul.wide.s32 	%rd36, %r70, 4;
	add.s64 	%rd37, %rd1, %rd36;
	ld.global.u32 	%r253, [%rd37];
	and.b32  	%r254, %r253, 1;
	setp.eq.b32 	%p43, %r254, 1;
	not.pred 	%p44, %p43;
	selp.b32 	%r713, -1, %r253, %p43;
	selp.u32 	%r255, 1, 0, %p44;
	add.s32 	%r690, %r690, %r255;

$L__BB1_30:
	add.s32 	%r75, %r70, %r1;
	setp.ge.s32 	%p45, %r75, %r191;
	mov.u32 	%r715, %r717;
	@%p45 bra 	$L__BB1_32;

	mul.wide.s32 	%rd38, %r75, 4;
	add.s64 	%rd39, %rd1, %rd38;
	ld.global.u32 	%r257, [%rd39];
	and.b32  	%r258, %r257, 1;
	setp.eq.b32 	%p46, %r258, 1;
	not.pred 	%p47, %p46;
	selp.b32 	%r715, -1, %r257, %p46;
	selp.u32 	%r259, 1, 0, %p47;
	add.s32 	%r690, %r690, %r259;

$L__BB1_32:
	add.s32 	%r80, %r75, %r1;
	setp.ge.s32 	%p48, %r80, %r191;
	@%p48 bra 	$L__BB1_34;

	mul.wide.s32 	%rd40, %r80, 4;
	add.s64 	%rd41, %rd1, %rd40;
	ld.global.u32 	%r261, [%rd41];
	and.b32  	%r262, %r261, 1;
	setp.eq.b32 	%p49, %r262, 1;
	not.pred 	%p50, %p49;
	selp.b32 	%r717, -1, %r261, %p49;
	selp.u32 	%r263, 1, 0, %p50;
	add.s32 	%r690, %r690, %r263;

$L__BB1_34:
	shl.b32 	%r264, %r3, 2;
	mov.u32 	%r265, _ZZ9reductionIiEvPT_S0_E5sdata;
	add.s32 	%r85, %r265, %r264;
	st.shared.u32 	[%r85], %r690;
	bar.sync 	0;
	setp.gt.u32 	%p51, %r3, 511;
	setp.lt.u32 	%p52, %r1, 1024;
	or.pred  	%p53, %p52, %p51;
	@%p53 bra 	$L__BB1_36;

	ld.shared.u32 	%r266, [%r85+2048];
	add.s32 	%r690, %r266, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_36:
	bar.sync 	0;
	setp.gt.u32 	%p54, %r3, 255;
	setp.lt.u32 	%p55, %r1, 512;
	or.pred  	%p56, %p55, %p54;
	@%p56 bra 	$L__BB1_38;

	ld.shared.u32 	%r267, [%r85+1024];
	add.s32 	%r690, %r267, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_38:
	bar.sync 	0;
	setp.gt.u32 	%p57, %r3, 127;
	setp.lt.u32 	%p58, %r1, 256;
	or.pred  	%p59, %p58, %p57;
	@%p59 bra 	$L__BB1_40;

	ld.shared.u32 	%r268, [%r85+512];
	add.s32 	%r690, %r268, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_40:
	bar.sync 	0;
	setp.gt.u32 	%p60, %r3, 63;
	setp.lt.u32 	%p61, %r1, 128;
	or.pred  	%p62, %p61, %p60;
	@%p62 bra 	$L__BB1_42;

	ld.shared.u32 	%r269, [%r85+256];
	add.s32 	%r690, %r269, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_42:
	bar.sync 	0;
	setp.gt.u32 	%p63, %r3, 31;
	setp.lt.u32 	%p64, %r1, 64;
	or.pred  	%p65, %p64, %p63;
	@%p65 bra 	$L__BB1_44;

	ld.shared.u32 	%r270, [%r85+128];
	add.s32 	%r690, %r270, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_44:
	bar.sync 	0;
	setp.gt.u32 	%p66, %r3, 15;
	setp.lt.u32 	%p67, %r1, 32;
	or.pred  	%p68, %p67, %p66;
	@%p68 bra 	$L__BB1_46;

	ld.shared.u32 	%r271, [%r85+64];
	add.s32 	%r690, %r271, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_46:
	bar.sync 	0;
	setp.gt.u32 	%p69, %r3, 7;
	setp.lt.u32 	%p70, %r1, 16;
	or.pred  	%p71, %p70, %p69;
	@%p71 bra 	$L__BB1_48;

	ld.shared.u32 	%r272, [%r85+32];
	add.s32 	%r690, %r272, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_48:
	bar.sync 	0;
	setp.gt.u32 	%p72, %r3, 3;
	setp.lt.u32 	%p73, %r1, 8;
	or.pred  	%p74, %p73, %p72;
	@%p74 bra 	$L__BB1_50;

	ld.shared.u32 	%r273, [%r85+16];
	add.s32 	%r690, %r273, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_50:
	bar.sync 	0;
	setp.gt.u32 	%p75, %r3, 1;
	setp.lt.u32 	%p76, %r1, 4;
	or.pred  	%p77, %p76, %p75;
	@%p77 bra 	$L__BB1_52;

	ld.shared.u32 	%r274, [%r85+8];
	add.s32 	%r690, %r274, %r690;
	st.shared.u32 	[%r85], %r690;

$L__BB1_52:
	bar.sync 	0;
	setp.lt.u32 	%p78, %r1, 2;
	or.pred  	%p80, %p78, %p1;
	@%p80 bra 	$L__BB1_54;

	ld.shared.u32 	%r275, [_ZZ9reductionIiEvPT_S0_E5sdata+4];
	add.s32 	%r690, %r275, %r690;
	st.shared.u32 	[_ZZ9reductionIiEvPT_S0_E5sdata], %r690;

$L__BB1_54:
	bar.sync 	0;
	@%p1 bra 	$L__BB1_58;

	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r690;
	mul.wide.s32 	%rd42, %r4, 4;
	add.s64 	%rd4, %rd3, %rd42;

$L__BB1_56:
	ld.volatile.global.u32 	%r276, [%rd4];
	setp.eq.s32 	%p82, %r276, 0;
	@%p82 bra 	$L__BB1_56;

	ld.volatile.global.u32 	%r277, [%rd4];
	add.s32 	%r278, %r690, %r277;
	st.volatile.global.u32 	[%rd4+4], %r278;
	add.s32 	%r279, %r277, -1;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r279;

$L__BB1_58:
	bar.sync 	0;
	shr.u32 	%r282, %r687, 31;
	xor.b32  	%r281, %r282, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r281, 0; 
	vote.ballot.b32 	%r280, %p1; 
	}
	// end inline asm
	and.b32  	%r107, %r3, 31;
	mov.u32 	%r283, -1;
	shl.b32 	%r284, %r283, %r107;
	not.b32 	%r108, %r284;
	and.b32  	%r285, %r280, %r108;
	popc.b32 	%r109, %r285;
	setp.ne.s32 	%p83, %r107, 31;
	shr.u32 	%r286, %r3, 3;
	and.b32  	%r287, %r286, 536870908;
	mov.u32 	%r288, _ZZ24block_binary_prefix_sumsPiiE5sdata;
	add.s32 	%r110, %r288, %r287;
	@%p83 bra 	$L__BB1_60;

	add.s32 	%r289, %r109, %r281;
	st.shared.u32 	[%r110], %r289;

$L__BB1_60:
	bar.sync 	0;
	add.s32 	%r111, %r288, %r264;
	@%p63 bra 	$L__BB1_62;

	ld.shared.u32 	%r294, [%r111];
	mov.u32 	%r293, 1;
	mov.u32 	%r295, %r294;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r295, %r293, 0x0; @p add.s32 r0, r0, %r295; mov.s32 %r295, r0;}
	// end inline asm
	mov.u32 	%r296, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r295, %r296, 0x0; @p add.s32 r0, r0, %r295; mov.s32 %r295, r0;}
	// end inline asm
	mov.u32 	%r299, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r295, %r299, 0x0; @p add.s32 r0, r0, %r295; mov.s32 %r295, r0;}
	// end inline asm
	mov.u32 	%r302, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r295, %r302, 0x0; @p add.s32 r0, r0, %r295; mov.s32 %r295, r0;}
	// end inline asm
	mov.u32 	%r305, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r295, %r305, 0x0; @p add.s32 r0, r0, %r295; mov.s32 %r295, r0;}
	// end inline asm
	sub.s32 	%r307, %r295, %r294;
	st.shared.u32 	[%r111], %r307;

$L__BB1_62:
	bar.sync 	0;
	ld.shared.u32 	%r308, [%r110];
	add.s32 	%r112, %r308, %r109;
	ld.shared.u32 	%r113, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	add.s32 	%r114, %r1, -1;
	setp.ne.s32 	%p85, %r3, %r114;
	@%p85 bra 	$L__BB1_64;

	add.s32 	%r309, %r112, %r281;
	ld.shared.u32 	%r310, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r311, %r309, %r310;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r311;

$L__BB1_64:
	add.s32 	%r115, %r112, %r113;
	setp.lt.s32 	%p86, %r687, 0;
	@%p86 bra 	$L__BB1_66;

	mul.wide.s32 	%rd43, %r115, 4;
	add.s64 	%rd44, %rd2, %rd43;
	st.global.u32 	[%rd44], %r687;

$L__BB1_66:
	shr.u32 	%r314, %r689, 31;
	xor.b32  	%r313, %r314, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r313, 0; 
	vote.ballot.b32 	%r312, %p1; 
	}
	// end inline asm
	and.b32  	%r315, %r312, %r108;
	popc.b32 	%r117, %r315;
	@%p83 bra 	$L__BB1_68;

	add.s32 	%r316, %r117, %r313;
	st.shared.u32 	[%r110], %r316;

$L__BB1_68:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_70;

	ld.shared.u32 	%r319, [%r111];
	mov.u32 	%r318, 1;
	mov.u32 	%r320, %r319;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r320, %r318, 0x0; @p add.s32 r0, r0, %r320; mov.s32 %r320, r0;}
	// end inline asm
	mov.u32 	%r321, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r320, %r321, 0x0; @p add.s32 r0, r0, %r320; mov.s32 %r320, r0;}
	// end inline asm
	mov.u32 	%r324, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r320, %r324, 0x0; @p add.s32 r0, r0, %r320; mov.s32 %r320, r0;}
	// end inline asm
	mov.u32 	%r327, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r320, %r327, 0x0; @p add.s32 r0, r0, %r320; mov.s32 %r320, r0;}
	// end inline asm
	mov.u32 	%r330, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r320, %r330, 0x0; @p add.s32 r0, r0, %r320; mov.s32 %r320, r0;}
	// end inline asm
	sub.s32 	%r332, %r320, %r319;
	st.shared.u32 	[%r111], %r332;

$L__BB1_70:
	bar.sync 	0;
	ld.shared.u32 	%r333, [%r110];
	add.s32 	%r118, %r333, %r117;
	ld.shared.u32 	%r119, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_72;

	add.s32 	%r334, %r118, %r313;
	ld.shared.u32 	%r335, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r336, %r334, %r335;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r336;

$L__BB1_72:
	add.s32 	%r120, %r118, %r119;
	setp.lt.s32 	%p90, %r689, 0;
	@%p90 bra 	$L__BB1_74;

	mul.wide.s32 	%rd45, %r120, 4;
	add.s64 	%rd46, %rd2, %rd45;
	st.global.u32 	[%rd46], %r689;

$L__BB1_74:
	shr.u32 	%r339, %r691, 31;
	xor.b32  	%r338, %r339, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r338, 0; 
	vote.ballot.b32 	%r337, %p1; 
	}
	// end inline asm
	and.b32  	%r340, %r337, %r108;
	popc.b32 	%r122, %r340;
	@%p83 bra 	$L__BB1_76;

	add.s32 	%r341, %r122, %r338;
	st.shared.u32 	[%r110], %r341;

$L__BB1_76:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_78;

	ld.shared.u32 	%r344, [%r111];
	mov.u32 	%r343, 1;
	mov.u32 	%r345, %r344;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r345, %r343, 0x0; @p add.s32 r0, r0, %r345; mov.s32 %r345, r0;}
	// end inline asm
	mov.u32 	%r346, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r345, %r346, 0x0; @p add.s32 r0, r0, %r345; mov.s32 %r345, r0;}
	// end inline asm
	mov.u32 	%r349, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r345, %r349, 0x0; @p add.s32 r0, r0, %r345; mov.s32 %r345, r0;}
	// end inline asm
	mov.u32 	%r352, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r345, %r352, 0x0; @p add.s32 r0, r0, %r345; mov.s32 %r345, r0;}
	// end inline asm
	mov.u32 	%r355, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r345, %r355, 0x0; @p add.s32 r0, r0, %r345; mov.s32 %r345, r0;}
	// end inline asm
	sub.s32 	%r357, %r345, %r344;
	st.shared.u32 	[%r111], %r357;

$L__BB1_78:
	bar.sync 	0;
	ld.shared.u32 	%r358, [%r110];
	add.s32 	%r123, %r358, %r122;
	ld.shared.u32 	%r124, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_80;

	add.s32 	%r359, %r123, %r338;
	ld.shared.u32 	%r360, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r361, %r359, %r360;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r361;

$L__BB1_80:
	add.s32 	%r125, %r123, %r124;
	setp.lt.s32 	%p94, %r691, 0;
	@%p94 bra 	$L__BB1_82;

	mul.wide.s32 	%rd47, %r125, 4;
	add.s64 	%rd48, %rd2, %rd47;
	st.global.u32 	[%rd48], %r691;

$L__BB1_82:
	shr.u32 	%r364, %r693, 31;
	xor.b32  	%r363, %r364, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r363, 0; 
	vote.ballot.b32 	%r362, %p1; 
	}
	// end inline asm
	and.b32  	%r365, %r362, %r108;
	popc.b32 	%r127, %r365;
	@%p83 bra 	$L__BB1_84;

	add.s32 	%r366, %r127, %r363;
	st.shared.u32 	[%r110], %r366;

$L__BB1_84:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_86;

	ld.shared.u32 	%r369, [%r111];
	mov.u32 	%r368, 1;
	mov.u32 	%r370, %r369;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r370, %r368, 0x0; @p add.s32 r0, r0, %r370; mov.s32 %r370, r0;}
	// end inline asm
	mov.u32 	%r371, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r370, %r371, 0x0; @p add.s32 r0, r0, %r370; mov.s32 %r370, r0;}
	// end inline asm
	mov.u32 	%r374, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r370, %r374, 0x0; @p add.s32 r0, r0, %r370; mov.s32 %r370, r0;}
	// end inline asm
	mov.u32 	%r377, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r370, %r377, 0x0; @p add.s32 r0, r0, %r370; mov.s32 %r370, r0;}
	// end inline asm
	mov.u32 	%r380, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r370, %r380, 0x0; @p add.s32 r0, r0, %r370; mov.s32 %r370, r0;}
	// end inline asm
	sub.s32 	%r382, %r370, %r369;
	st.shared.u32 	[%r111], %r382;

$L__BB1_86:
	bar.sync 	0;
	ld.shared.u32 	%r383, [%r110];
	add.s32 	%r128, %r383, %r127;
	ld.shared.u32 	%r129, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_88;

	add.s32 	%r384, %r128, %r363;
	ld.shared.u32 	%r385, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r386, %r384, %r385;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r386;

$L__BB1_88:
	add.s32 	%r130, %r128, %r129;
	setp.lt.s32 	%p98, %r693, 0;
	@%p98 bra 	$L__BB1_90;

	mul.wide.s32 	%rd49, %r130, 4;
	add.s64 	%rd50, %rd2, %rd49;
	st.global.u32 	[%rd50], %r693;

$L__BB1_90:
	shr.u32 	%r389, %r695, 31;
	xor.b32  	%r388, %r389, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r388, 0; 
	vote.ballot.b32 	%r387, %p1; 
	}
	// end inline asm
	and.b32  	%r390, %r387, %r108;
	popc.b32 	%r132, %r390;
	@%p83 bra 	$L__BB1_92;

	add.s32 	%r391, %r132, %r388;
	st.shared.u32 	[%r110], %r391;

$L__BB1_92:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_94;

	ld.shared.u32 	%r394, [%r111];
	mov.u32 	%r393, 1;
	mov.u32 	%r395, %r394;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r395, %r393, 0x0; @p add.s32 r0, r0, %r395; mov.s32 %r395, r0;}
	// end inline asm
	mov.u32 	%r396, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r395, %r396, 0x0; @p add.s32 r0, r0, %r395; mov.s32 %r395, r0;}
	// end inline asm
	mov.u32 	%r399, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r395, %r399, 0x0; @p add.s32 r0, r0, %r395; mov.s32 %r395, r0;}
	// end inline asm
	mov.u32 	%r402, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r395, %r402, 0x0; @p add.s32 r0, r0, %r395; mov.s32 %r395, r0;}
	// end inline asm
	mov.u32 	%r405, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r395, %r405, 0x0; @p add.s32 r0, r0, %r395; mov.s32 %r395, r0;}
	// end inline asm
	sub.s32 	%r407, %r395, %r394;
	st.shared.u32 	[%r111], %r407;

$L__BB1_94:
	bar.sync 	0;
	ld.shared.u32 	%r408, [%r110];
	add.s32 	%r133, %r408, %r132;
	ld.shared.u32 	%r134, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_96;

	add.s32 	%r409, %r133, %r388;
	ld.shared.u32 	%r410, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r411, %r409, %r410;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r411;

$L__BB1_96:
	add.s32 	%r135, %r133, %r134;
	setp.lt.s32 	%p102, %r695, 0;
	@%p102 bra 	$L__BB1_98;

	mul.wide.s32 	%rd51, %r135, 4;
	add.s64 	%rd52, %rd2, %rd51;
	st.global.u32 	[%rd52], %r695;

$L__BB1_98:
	shr.u32 	%r414, %r697, 31;
	xor.b32  	%r413, %r414, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r413, 0; 
	vote.ballot.b32 	%r412, %p1; 
	}
	// end inline asm
	and.b32  	%r415, %r412, %r108;
	popc.b32 	%r137, %r415;
	@%p83 bra 	$L__BB1_100;

	add.s32 	%r416, %r137, %r413;
	st.shared.u32 	[%r110], %r416;

$L__BB1_100:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_102;

	ld.shared.u32 	%r419, [%r111];
	mov.u32 	%r418, 1;
	mov.u32 	%r420, %r419;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r420, %r418, 0x0; @p add.s32 r0, r0, %r420; mov.s32 %r420, r0;}
	// end inline asm
	mov.u32 	%r421, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r420, %r421, 0x0; @p add.s32 r0, r0, %r420; mov.s32 %r420, r0;}
	// end inline asm
	mov.u32 	%r424, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r420, %r424, 0x0; @p add.s32 r0, r0, %r420; mov.s32 %r420, r0;}
	// end inline asm
	mov.u32 	%r427, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r420, %r427, 0x0; @p add.s32 r0, r0, %r420; mov.s32 %r420, r0;}
	// end inline asm
	mov.u32 	%r430, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r420, %r430, 0x0; @p add.s32 r0, r0, %r420; mov.s32 %r420, r0;}
	// end inline asm
	sub.s32 	%r432, %r420, %r419;
	st.shared.u32 	[%r111], %r432;

$L__BB1_102:
	bar.sync 	0;
	ld.shared.u32 	%r433, [%r110];
	add.s32 	%r138, %r433, %r137;
	ld.shared.u32 	%r139, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_104;

	add.s32 	%r434, %r138, %r413;
	ld.shared.u32 	%r435, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r436, %r434, %r435;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r436;

$L__BB1_104:
	add.s32 	%r140, %r138, %r139;
	setp.lt.s32 	%p106, %r697, 0;
	@%p106 bra 	$L__BB1_106;

	mul.wide.s32 	%rd53, %r140, 4;
	add.s64 	%rd54, %rd2, %rd53;
	st.global.u32 	[%rd54], %r697;

$L__BB1_106:
	shr.u32 	%r439, %r699, 31;
	xor.b32  	%r438, %r439, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r438, 0; 
	vote.ballot.b32 	%r437, %p1; 
	}
	// end inline asm
	and.b32  	%r440, %r437, %r108;
	popc.b32 	%r142, %r440;
	@%p83 bra 	$L__BB1_108;

	add.s32 	%r441, %r142, %r438;
	st.shared.u32 	[%r110], %r441;

$L__BB1_108:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_110;

	ld.shared.u32 	%r444, [%r111];
	mov.u32 	%r443, 1;
	mov.u32 	%r445, %r444;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r445, %r443, 0x0; @p add.s32 r0, r0, %r445; mov.s32 %r445, r0;}
	// end inline asm
	mov.u32 	%r446, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r445, %r446, 0x0; @p add.s32 r0, r0, %r445; mov.s32 %r445, r0;}
	// end inline asm
	mov.u32 	%r449, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r445, %r449, 0x0; @p add.s32 r0, r0, %r445; mov.s32 %r445, r0;}
	// end inline asm
	mov.u32 	%r452, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r445, %r452, 0x0; @p add.s32 r0, r0, %r445; mov.s32 %r445, r0;}
	// end inline asm
	mov.u32 	%r455, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r445, %r455, 0x0; @p add.s32 r0, r0, %r445; mov.s32 %r445, r0;}
	// end inline asm
	sub.s32 	%r457, %r445, %r444;
	st.shared.u32 	[%r111], %r457;

$L__BB1_110:
	bar.sync 	0;
	ld.shared.u32 	%r458, [%r110];
	add.s32 	%r143, %r458, %r142;
	ld.shared.u32 	%r144, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_112;

	add.s32 	%r459, %r143, %r438;
	ld.shared.u32 	%r460, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r461, %r459, %r460;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r461;

$L__BB1_112:
	add.s32 	%r145, %r143, %r144;
	setp.lt.s32 	%p110, %r699, 0;
	@%p110 bra 	$L__BB1_114;

	mul.wide.s32 	%rd55, %r145, 4;
	add.s64 	%rd56, %rd2, %rd55;
	st.global.u32 	[%rd56], %r699;

$L__BB1_114:
	shr.u32 	%r464, %r701, 31;
	xor.b32  	%r463, %r464, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r463, 0; 
	vote.ballot.b32 	%r462, %p1; 
	}
	// end inline asm
	and.b32  	%r465, %r462, %r108;
	popc.b32 	%r147, %r465;
	@%p83 bra 	$L__BB1_116;

	add.s32 	%r466, %r147, %r463;
	st.shared.u32 	[%r110], %r466;

$L__BB1_116:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_118;

	ld.shared.u32 	%r469, [%r111];
	mov.u32 	%r468, 1;
	mov.u32 	%r470, %r469;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r470, %r468, 0x0; @p add.s32 r0, r0, %r470; mov.s32 %r470, r0;}
	// end inline asm
	mov.u32 	%r471, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r470, %r471, 0x0; @p add.s32 r0, r0, %r470; mov.s32 %r470, r0;}
	// end inline asm
	mov.u32 	%r474, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r470, %r474, 0x0; @p add.s32 r0, r0, %r470; mov.s32 %r470, r0;}
	// end inline asm
	mov.u32 	%r477, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r470, %r477, 0x0; @p add.s32 r0, r0, %r470; mov.s32 %r470, r0;}
	// end inline asm
	mov.u32 	%r480, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r470, %r480, 0x0; @p add.s32 r0, r0, %r470; mov.s32 %r470, r0;}
	// end inline asm
	sub.s32 	%r482, %r470, %r469;
	st.shared.u32 	[%r111], %r482;

$L__BB1_118:
	bar.sync 	0;
	ld.shared.u32 	%r483, [%r110];
	add.s32 	%r148, %r483, %r147;
	ld.shared.u32 	%r149, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_120;

	add.s32 	%r484, %r148, %r463;
	ld.shared.u32 	%r485, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r486, %r484, %r485;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r486;

$L__BB1_120:
	add.s32 	%r150, %r148, %r149;
	setp.lt.s32 	%p114, %r701, 0;
	@%p114 bra 	$L__BB1_122;

	mul.wide.s32 	%rd57, %r150, 4;
	add.s64 	%rd58, %rd2, %rd57;
	st.global.u32 	[%rd58], %r701;

$L__BB1_122:
	shr.u32 	%r489, %r703, 31;
	xor.b32  	%r488, %r489, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r488, 0; 
	vote.ballot.b32 	%r487, %p1; 
	}
	// end inline asm
	and.b32  	%r490, %r487, %r108;
	popc.b32 	%r152, %r490;
	@%p83 bra 	$L__BB1_124;

	add.s32 	%r491, %r152, %r488;
	st.shared.u32 	[%r110], %r491;

$L__BB1_124:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_126;

	ld.shared.u32 	%r494, [%r111];
	mov.u32 	%r493, 1;
	mov.u32 	%r495, %r494;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r495, %r493, 0x0; @p add.s32 r0, r0, %r495; mov.s32 %r495, r0;}
	// end inline asm
	mov.u32 	%r496, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r495, %r496, 0x0; @p add.s32 r0, r0, %r495; mov.s32 %r495, r0;}
	// end inline asm
	mov.u32 	%r499, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r495, %r499, 0x0; @p add.s32 r0, r0, %r495; mov.s32 %r495, r0;}
	// end inline asm
	mov.u32 	%r502, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r495, %r502, 0x0; @p add.s32 r0, r0, %r495; mov.s32 %r495, r0;}
	// end inline asm
	mov.u32 	%r505, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r495, %r505, 0x0; @p add.s32 r0, r0, %r495; mov.s32 %r495, r0;}
	// end inline asm
	sub.s32 	%r507, %r495, %r494;
	st.shared.u32 	[%r111], %r507;

$L__BB1_126:
	bar.sync 	0;
	ld.shared.u32 	%r508, [%r110];
	add.s32 	%r153, %r508, %r152;
	ld.shared.u32 	%r154, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_128;

	add.s32 	%r509, %r153, %r488;
	ld.shared.u32 	%r510, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r511, %r509, %r510;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r511;

$L__BB1_128:
	add.s32 	%r155, %r153, %r154;
	setp.lt.s32 	%p118, %r703, 0;
	@%p118 bra 	$L__BB1_130;

	mul.wide.s32 	%rd59, %r155, 4;
	add.s64 	%rd60, %rd2, %rd59;
	st.global.u32 	[%rd60], %r703;

$L__BB1_130:
	shr.u32 	%r514, %r705, 31;
	xor.b32  	%r513, %r514, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r513, 0; 
	vote.ballot.b32 	%r512, %p1; 
	}
	// end inline asm
	and.b32  	%r515, %r512, %r108;
	popc.b32 	%r157, %r515;
	@%p83 bra 	$L__BB1_132;

	add.s32 	%r516, %r157, %r513;
	st.shared.u32 	[%r110], %r516;

$L__BB1_132:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_134;

	ld.shared.u32 	%r519, [%r111];
	mov.u32 	%r518, 1;
	mov.u32 	%r520, %r519;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r520, %r518, 0x0; @p add.s32 r0, r0, %r520; mov.s32 %r520, r0;}
	// end inline asm
	mov.u32 	%r521, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r520, %r521, 0x0; @p add.s32 r0, r0, %r520; mov.s32 %r520, r0;}
	// end inline asm
	mov.u32 	%r524, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r520, %r524, 0x0; @p add.s32 r0, r0, %r520; mov.s32 %r520, r0;}
	// end inline asm
	mov.u32 	%r527, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r520, %r527, 0x0; @p add.s32 r0, r0, %r520; mov.s32 %r520, r0;}
	// end inline asm
	mov.u32 	%r530, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r520, %r530, 0x0; @p add.s32 r0, r0, %r520; mov.s32 %r520, r0;}
	// end inline asm
	sub.s32 	%r532, %r520, %r519;
	st.shared.u32 	[%r111], %r532;

$L__BB1_134:
	bar.sync 	0;
	ld.shared.u32 	%r533, [%r110];
	add.s32 	%r158, %r533, %r157;
	ld.shared.u32 	%r159, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_136;

	add.s32 	%r534, %r158, %r513;
	ld.shared.u32 	%r535, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r536, %r534, %r535;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r536;

$L__BB1_136:
	add.s32 	%r160, %r158, %r159;
	setp.lt.s32 	%p122, %r705, 0;
	@%p122 bra 	$L__BB1_138;

	mul.wide.s32 	%rd61, %r160, 4;
	add.s64 	%rd62, %rd2, %rd61;
	st.global.u32 	[%rd62], %r705;

$L__BB1_138:
	shr.u32 	%r539, %r707, 31;
	xor.b32  	%r538, %r539, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r538, 0; 
	vote.ballot.b32 	%r537, %p1; 
	}
	// end inline asm
	and.b32  	%r540, %r537, %r108;
	popc.b32 	%r162, %r540;
	@%p83 bra 	$L__BB1_140;

	add.s32 	%r541, %r162, %r538;
	st.shared.u32 	[%r110], %r541;

$L__BB1_140:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_142;

	ld.shared.u32 	%r544, [%r111];
	mov.u32 	%r543, 1;
	mov.u32 	%r545, %r544;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r545, %r543, 0x0; @p add.s32 r0, r0, %r545; mov.s32 %r545, r0;}
	// end inline asm
	mov.u32 	%r546, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r545, %r546, 0x0; @p add.s32 r0, r0, %r545; mov.s32 %r545, r0;}
	// end inline asm
	mov.u32 	%r549, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r545, %r549, 0x0; @p add.s32 r0, r0, %r545; mov.s32 %r545, r0;}
	// end inline asm
	mov.u32 	%r552, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r545, %r552, 0x0; @p add.s32 r0, r0, %r545; mov.s32 %r545, r0;}
	// end inline asm
	mov.u32 	%r555, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r545, %r555, 0x0; @p add.s32 r0, r0, %r545; mov.s32 %r545, r0;}
	// end inline asm
	sub.s32 	%r557, %r545, %r544;
	st.shared.u32 	[%r111], %r557;

$L__BB1_142:
	bar.sync 	0;
	ld.shared.u32 	%r558, [%r110];
	add.s32 	%r163, %r558, %r162;
	ld.shared.u32 	%r164, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_144;

	add.s32 	%r559, %r163, %r538;
	ld.shared.u32 	%r560, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r561, %r559, %r560;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r561;

$L__BB1_144:
	add.s32 	%r165, %r163, %r164;
	setp.lt.s32 	%p126, %r707, 0;
	@%p126 bra 	$L__BB1_146;

	mul.wide.s32 	%rd63, %r165, 4;
	add.s64 	%rd64, %rd2, %rd63;
	st.global.u32 	[%rd64], %r707;

$L__BB1_146:
	shr.u32 	%r564, %r709, 31;
	xor.b32  	%r563, %r564, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r563, 0; 
	vote.ballot.b32 	%r562, %p1; 
	}
	// end inline asm
	and.b32  	%r565, %r562, %r108;
	popc.b32 	%r167, %r565;
	@%p83 bra 	$L__BB1_148;

	add.s32 	%r566, %r167, %r563;
	st.shared.u32 	[%r110], %r566;

$L__BB1_148:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_150;

	ld.shared.u32 	%r569, [%r111];
	mov.u32 	%r568, 1;
	mov.u32 	%r570, %r569;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r570, %r568, 0x0; @p add.s32 r0, r0, %r570; mov.s32 %r570, r0;}
	// end inline asm
	mov.u32 	%r571, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r570, %r571, 0x0; @p add.s32 r0, r0, %r570; mov.s32 %r570, r0;}
	// end inline asm
	mov.u32 	%r574, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r570, %r574, 0x0; @p add.s32 r0, r0, %r570; mov.s32 %r570, r0;}
	// end inline asm
	mov.u32 	%r577, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r570, %r577, 0x0; @p add.s32 r0, r0, %r570; mov.s32 %r570, r0;}
	// end inline asm
	mov.u32 	%r580, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r570, %r580, 0x0; @p add.s32 r0, r0, %r570; mov.s32 %r570, r0;}
	// end inline asm
	sub.s32 	%r582, %r570, %r569;
	st.shared.u32 	[%r111], %r582;

$L__BB1_150:
	bar.sync 	0;
	ld.shared.u32 	%r583, [%r110];
	add.s32 	%r168, %r583, %r167;
	ld.shared.u32 	%r169, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_152;

	add.s32 	%r584, %r168, %r563;
	ld.shared.u32 	%r585, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r586, %r584, %r585;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r586;

$L__BB1_152:
	add.s32 	%r170, %r168, %r169;
	setp.lt.s32 	%p130, %r709, 0;
	@%p130 bra 	$L__BB1_154;

	mul.wide.s32 	%rd65, %r170, 4;
	add.s64 	%rd66, %rd2, %rd65;
	st.global.u32 	[%rd66], %r709;

$L__BB1_154:
	shr.u32 	%r589, %r711, 31;
	xor.b32  	%r588, %r589, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r588, 0; 
	vote.ballot.b32 	%r587, %p1; 
	}
	// end inline asm
	and.b32  	%r590, %r587, %r108;
	popc.b32 	%r172, %r590;
	@%p83 bra 	$L__BB1_156;

	add.s32 	%r591, %r172, %r588;
	st.shared.u32 	[%r110], %r591;

$L__BB1_156:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_158;

	ld.shared.u32 	%r594, [%r111];
	mov.u32 	%r593, 1;
	mov.u32 	%r595, %r594;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r595, %r593, 0x0; @p add.s32 r0, r0, %r595; mov.s32 %r595, r0;}
	// end inline asm
	mov.u32 	%r596, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r595, %r596, 0x0; @p add.s32 r0, r0, %r595; mov.s32 %r595, r0;}
	// end inline asm
	mov.u32 	%r599, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r595, %r599, 0x0; @p add.s32 r0, r0, %r595; mov.s32 %r595, r0;}
	// end inline asm
	mov.u32 	%r602, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r595, %r602, 0x0; @p add.s32 r0, r0, %r595; mov.s32 %r595, r0;}
	// end inline asm
	mov.u32 	%r605, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r595, %r605, 0x0; @p add.s32 r0, r0, %r595; mov.s32 %r595, r0;}
	// end inline asm
	sub.s32 	%r607, %r595, %r594;
	st.shared.u32 	[%r111], %r607;

$L__BB1_158:
	bar.sync 	0;
	ld.shared.u32 	%r608, [%r110];
	add.s32 	%r173, %r608, %r172;
	ld.shared.u32 	%r174, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_160;

	add.s32 	%r609, %r173, %r588;
	ld.shared.u32 	%r610, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r611, %r609, %r610;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r611;

$L__BB1_160:
	add.s32 	%r175, %r173, %r174;
	setp.lt.s32 	%p134, %r711, 0;
	@%p134 bra 	$L__BB1_162;

	mul.wide.s32 	%rd67, %r175, 4;
	add.s64 	%rd68, %rd2, %rd67;
	st.global.u32 	[%rd68], %r711;

$L__BB1_162:
	shr.u32 	%r614, %r713, 31;
	xor.b32  	%r613, %r614, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r613, 0; 
	vote.ballot.b32 	%r612, %p1; 
	}
	// end inline asm
	and.b32  	%r615, %r612, %r108;
	popc.b32 	%r177, %r615;
	@%p83 bra 	$L__BB1_164;

	add.s32 	%r616, %r177, %r613;
	st.shared.u32 	[%r110], %r616;

$L__BB1_164:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_166;

	ld.shared.u32 	%r619, [%r111];
	mov.u32 	%r618, 1;
	mov.u32 	%r620, %r619;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r620, %r618, 0x0; @p add.s32 r0, r0, %r620; mov.s32 %r620, r0;}
	// end inline asm
	mov.u32 	%r621, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r620, %r621, 0x0; @p add.s32 r0, r0, %r620; mov.s32 %r620, r0;}
	// end inline asm
	mov.u32 	%r624, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r620, %r624, 0x0; @p add.s32 r0, r0, %r620; mov.s32 %r620, r0;}
	// end inline asm
	mov.u32 	%r627, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r620, %r627, 0x0; @p add.s32 r0, r0, %r620; mov.s32 %r620, r0;}
	// end inline asm
	mov.u32 	%r630, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r620, %r630, 0x0; @p add.s32 r0, r0, %r620; mov.s32 %r620, r0;}
	// end inline asm
	sub.s32 	%r632, %r620, %r619;
	st.shared.u32 	[%r111], %r632;

$L__BB1_166:
	bar.sync 	0;
	ld.shared.u32 	%r633, [%r110];
	add.s32 	%r178, %r633, %r177;
	ld.shared.u32 	%r179, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_168;

	add.s32 	%r634, %r178, %r613;
	ld.shared.u32 	%r635, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r636, %r634, %r635;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r636;

$L__BB1_168:
	add.s32 	%r180, %r178, %r179;
	setp.lt.s32 	%p138, %r713, 0;
	@%p138 bra 	$L__BB1_170;

	mul.wide.s32 	%rd69, %r180, 4;
	add.s64 	%rd70, %rd2, %rd69;
	st.global.u32 	[%rd70], %r713;

$L__BB1_170:
	shr.u32 	%r639, %r715, 31;
	xor.b32  	%r638, %r639, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r638, 0; 
	vote.ballot.b32 	%r637, %p1; 
	}
	// end inline asm
	and.b32  	%r640, %r637, %r108;
	popc.b32 	%r182, %r640;
	@%p83 bra 	$L__BB1_172;

	add.s32 	%r641, %r182, %r638;
	st.shared.u32 	[%r110], %r641;

$L__BB1_172:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_174;

	ld.shared.u32 	%r644, [%r111];
	mov.u32 	%r643, 1;
	mov.u32 	%r645, %r644;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r645, %r643, 0x0; @p add.s32 r0, r0, %r645; mov.s32 %r645, r0;}
	// end inline asm
	mov.u32 	%r646, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r645, %r646, 0x0; @p add.s32 r0, r0, %r645; mov.s32 %r645, r0;}
	// end inline asm
	mov.u32 	%r649, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r645, %r649, 0x0; @p add.s32 r0, r0, %r645; mov.s32 %r645, r0;}
	// end inline asm
	mov.u32 	%r652, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r645, %r652, 0x0; @p add.s32 r0, r0, %r645; mov.s32 %r645, r0;}
	// end inline asm
	mov.u32 	%r655, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r645, %r655, 0x0; @p add.s32 r0, r0, %r645; mov.s32 %r645, r0;}
	// end inline asm
	sub.s32 	%r657, %r645, %r644;
	st.shared.u32 	[%r111], %r657;

$L__BB1_174:
	bar.sync 	0;
	ld.shared.u32 	%r658, [%r110];
	add.s32 	%r183, %r658, %r182;
	ld.shared.u32 	%r184, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_176;

	add.s32 	%r659, %r183, %r638;
	ld.shared.u32 	%r660, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r661, %r659, %r660;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r661;

$L__BB1_176:
	add.s32 	%r185, %r183, %r184;
	setp.lt.s32 	%p142, %r715, 0;
	@%p142 bra 	$L__BB1_178;

	mul.wide.s32 	%rd71, %r185, 4;
	add.s64 	%rd72, %rd2, %rd71;
	st.global.u32 	[%rd72], %r715;

$L__BB1_178:
	shr.u32 	%r664, %r717, 31;
	xor.b32  	%r663, %r664, 1;
	// begin inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r663, 0; 
	vote.ballot.b32 	%r662, %p1; 
	}
	// end inline asm
	and.b32  	%r665, %r662, %r108;
	popc.b32 	%r187, %r665;
	@%p83 bra 	$L__BB1_180;

	add.s32 	%r666, %r187, %r663;
	st.shared.u32 	[%r110], %r666;

$L__BB1_180:
	bar.sync 	0;
	@%p63 bra 	$L__BB1_182;

	ld.shared.u32 	%r669, [%r111];
	mov.u32 	%r668, 1;
	mov.u32 	%r670, %r669;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r670, %r668, 0x0; @p add.s32 r0, r0, %r670; mov.s32 %r670, r0;}
	// end inline asm
	mov.u32 	%r671, 2;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r670, %r671, 0x0; @p add.s32 r0, r0, %r670; mov.s32 %r670, r0;}
	// end inline asm
	mov.u32 	%r674, 4;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r670, %r674, 0x0; @p add.s32 r0, r0, %r670; mov.s32 %r670, r0;}
	// end inline asm
	mov.u32 	%r677, 8;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r670, %r677, 0x0; @p add.s32 r0, r0, %r670; mov.s32 %r670, r0;}
	// end inline asm
	mov.u32 	%r680, 16;
	// begin inline asm
	{ .reg .s32 r0; .reg .pred p; shfl.up.b32 r0|p, %r670, %r680, 0x0; @p add.s32 r0, r0, %r670; mov.s32 %r670, r0;}
	// end inline asm
	sub.s32 	%r682, %r670, %r669;
	st.shared.u32 	[%r111], %r682;

$L__BB1_182:
	bar.sync 	0;
	ld.shared.u32 	%r683, [%r110];
	add.s32 	%r188, %r683, %r187;
	ld.shared.u32 	%r189, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	bar.sync 	0;
	@%p85 bra 	$L__BB1_184;

	add.s32 	%r684, %r188, %r663;
	ld.shared.u32 	%r685, [_ZZ14select_copy_ifPiS_iPVj7is_evenE5count];
	add.s32 	%r686, %r684, %r685;
	st.shared.u32 	[_ZZ14select_copy_ifPiS_iPVj7is_evenE5count], %r686;

$L__BB1_184:
	add.s32 	%r190, %r188, %r189;
	setp.lt.s32 	%p146, %r717, 0;
	@%p146 bra 	$L__BB1_186;

	mul.wide.s32 	%rd73, %r190, 4;
	add.s64 	%rd74, %rd2, %rd73;
	st.global.u32 	[%rd74], %r717;

$L__BB1_186:
	ret;

}

